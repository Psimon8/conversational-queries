import streamlit as st
from openai import OpenAI
import pandas as pd
import json
import time
from collections import Counter
import re
import requests
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.express as px
from io import BytesIO

# Configuration de la page Streamlit
st.set_page_config(
    page_title="SEO Conversational Queries Optimizer",
    page_icon="üîç",
    layout="wide"
)

# Titre principal
st.title("üîç Optimiseur de Requ√™tes Conversationnelles SEO")
st.subheader("Analyse bas√©e sur les suggestions Google pour l'optimisation SEO")

# Configuration de l'API OpenAI
st.sidebar.header("‚öôÔ∏è Configuration")
api_key = st.sidebar.text_input("Cl√© API OpenAI", type="password", help="Votre cl√© API OpenAI pour GPT-4o mini")

if api_key:
    client = OpenAI(api_key=api_key)
    st.sidebar.success("‚úÖ API configur√©e")
else:
    st.sidebar.warning("‚ö†Ô∏è Veuillez entrer votre cl√© API OpenAI")
    client = None

# Fonctions utilitaires communes
def call_gpt4o_mini(prompt, max_retries=3):
    """Appel √† l'API GPT-4o mini avec gestion d'erreurs"""
    if not client:
        st.error("‚ùå Cl√© API manquante")
        return None
    
    for attempt in range(max_retries):
        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": "Tu es un expert SEO sp√©cialis√© dans l'analyse des requ√™tes conversationnelles et l'optimisation pour les moteurs de recherche."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=1500,
                temperature=0.7
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)
                continue
            else:
                st.error(f"‚ùå Erreur API apr√®s {max_retries} tentatives: {str(e)}")
                return None

def get_google_suggestions(keyword, lang='fr', max_suggestions=10):
    """R√©cup√®re les suggestions Google pour un mot-cl√©"""
    url = "https://suggestqueries.google.com/complete/search"
    params = {
        "q": keyword,
        "gl": lang,
        "client": "chrome",
        "_": str(int(time.time() * 1000))
    }
    
    try:
        response = requests.get(url, params=params, timeout=5)
        response.raise_for_status()
        suggestions = response.json()[1][:max_suggestions]
        return suggestions
    except Exception as e:
        st.error(f"‚ùå Erreur lors de la r√©cup√©ration des suggestions pour '{keyword}': {str(e)}")
        return []

def extract_questions_from_response(response_text):
    """Extrait les questions d'une r√©ponse de GPT"""
    if not response_text:
        return []
    
    patterns = [
        r'^\d+\.?\s*["\']?([^"\']+\?)["\']?',  # Format num√©rot√© avec ?
        r'^-\s*["\']?([^"\']+\?)["\']?',       # Format avec tirets avec ?
        r'^‚Ä¢\s*["\']?([^"\']+\?)["\']?'        # Format avec puces avec ?
    ]
    
    questions = []
    lines = response_text.split('\n')
    
    for line in lines:
        line = line.strip()
        if not line or not line.endswith('?'):
            continue
            
        for pattern in patterns:
            match = re.match(pattern, line, re.MULTILINE)
            if match:
                question = match.group(1).strip()
                if len(question) > 10:
                    questions.append(question)
                break
        else:
            # Si aucun pattern ne correspond mais que la ligne se termine par ?
            if line.endswith('?') and len(line) > 10:
                questions.append(line)
    
    return questions

def consolidate_and_deduplicate(questions_data, target_count):
    """Consolide et d√©duplique les questions en gardant les plus pertinentes"""
    if not questions_data:
        return []
    
    # Cr√©er un dictionnaire pour comptabiliser les occurrences et garder les m√©tadonn√©es
    question_stats = {}
    
    for item in questions_data:
        question = item['Question Conversationnelle'].strip()
        # Normalisation pour d√©tecter les similitudes
        normalized = re.sub(r'[^\w\s]', '', question.lower()).strip()
        
        if normalized not in question_stats:
            question_stats[normalized] = {
                'original_question': question,
                'count': 1,
                'suggestions': [item['Suggestion Google']],
                'keywords': [item['Mot-cl√©']],
                'first_occurrence': item
            }
        else:
            question_stats[normalized]['count'] += 1
            if item['Suggestion Google'] not in question_stats[normalized]['suggestions']:
                question_stats[normalized]['suggestions'].append(item['Suggestion Google'])
            if item['Mot-cl√©'] not in question_stats[normalized]['keywords']:
                question_stats[normalized]['keywords'].append(item['Mot-cl√©'])
    
    # Trier par nombre d'occurrences (pertinence) et prendre les meilleures
    sorted_questions = sorted(
        question_stats.values(),
        key=lambda x: (x['count'], len(x['keywords'])),
        reverse=True
    )
    
    # Prendre le nombre demand√© de questions
    final_questions = []
    for i, q_data in enumerate(sorted_questions[:target_count]):
        final_questions.append({
            'Requ√™tes Conversationnelles': q_data['original_question'],
            'Suggestion': q_data['suggestions'][0],  # Premi√®re suggestion associ√©e
            'Mot-cl√©': q_data['keywords'][0],  # Premier mot-cl√© associ√©
            'Score_Pertinence': q_data['count'],
            'Nb_Keywords': len(q_data['keywords']),
            'Nb_Suggestions': len(q_data['suggestions'])
        })
    
    return final_questions

def create_excel_file(df):
    """Cr√©e un fichier Excel avec formatage"""
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='Questions_Conversationnelles')
        
        # Acc√©der au workbook et worksheet pour le formatage
        workbook = writer.book
        worksheet = writer.sheets['Questions_Conversationnelles']
        
        # Ajuster la largeur des colonnes
        worksheet.column_dimensions['A'].width = 60  # Questions
        worksheet.column_dimensions['B'].width = 40  # Suggestions
        worksheet.column_dimensions['C'].width = 25  # Mots-cl√©s
        
        # Formatage de l'en-t√™te
        from openpyxl.styles import Font, PatternFill
        header_font = Font(bold=True)
        header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
        
        for cell in worksheet[1]:
            cell.font = header_font
            cell.fill = header_fill
    
    output.seek(0)
    return output

# Interface principale - Analyse par Suggestions Google
st.markdown("### üîç Analyse bas√©e sur les suggestions Google")

# Input pour les mots-cl√©s
keywords_input = st.text_area(
    "üéØ Entrez vos mots-cl√©s (un par ligne)",
    placeholder="restaurant paris\nh√¥tel luxe\nvoyage √©cologique",
    help="Entrez un ou plusieurs mots-cl√©s, un par ligne"
)

# Configuration am√©lior√©e
col1, col2, col3 = st.columns(3)
with col1:
    max_suggestions = st.slider(
        "Nombre de suggestions par mot-cl√©", 
        min_value=3, 
        max_value=15, 
        value=10,
        help="Nombre de suggestions Google √† r√©cup√©rer pour chaque mot-cl√©"
    )
with col2:
    final_questions_count = st.slider(
        "Nombre de questions finales",
        min_value=5,
        max_value=50,
        value=15,
        help="Nombre de questions conversationnelles √† conserver apr√®s consolidation"
    )
with col3:
    lang = st.selectbox("Langue", ["fr", "en", "es", "de", "it"], index=0)

if keywords_input and api_key:
    keywords = [kw.strip() for kw in keywords_input.split('\n') if kw.strip()]
    
    if st.button("üöÄ Analyser les suggestions", type="primary"):
        if not keywords:
            st.error("‚ùå Veuillez entrer au moins un mot-cl√©")
        else:
            # Progress tracking
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # Container pour les r√©sultats
            results_container = st.container()
            
            # √âtape 1: Collecte des suggestions
            status_text.text("‚è≥ √âtape 1/4: Collecte des suggestions Google...")
            all_suggestions = []
            
            for i, keyword in enumerate(keywords):
                suggestions = get_google_suggestions(keyword, lang, max_suggestions)
                
                for suggestion in suggestions:
                    all_suggestions.append({
                        'Mot-cl√©': keyword,
                        'Suggestion Google': suggestion
                    })
                
                progress_bar.progress((i + 1) * 20 // len(keywords))
                time.sleep(0.5)  # √âviter le rate limiting
            
            if not all_suggestions:
                st.error("‚ùå Aucune suggestion trouv√©e")
            else:
                st.info(f"‚úÖ {len(all_suggestions)} suggestions collect√©es pour {len(keywords)} mot(s)-cl√©(s)")
                
                # √âtape 2: G√©n√©ration des questions conversationnelles (10 par suggestion)
                status_text.text("‚è≥ √âtape 2/4: G√©n√©ration de 10 questions par suggestion...")
                
                all_questions_data = []
                processed = 0
                total_items = len(all_suggestions)
                
                for item in all_suggestions:
                    keyword = item['Mot-cl√©']
                    suggestion = item['Suggestion Google']
                    
                    prompt = f"""
                    Bas√© sur le mot-cl√© "{keyword}" et la suggestion Google "{suggestion}", 
                    g√©n√®re EXACTEMENT 10 questions conversationnelles SEO pertinentes au format question.
                    
                    Les questions doivent :
                    - √ätre naturelles et conversationnelles
                    - Optimis√©es pour la recherche vocale
                    - Pertinentes pour l'intention de recherche
                    - Se terminer par un point d'interrogation
                    - √ätre vari√©es dans leur formulation
                    
                    Pr√©sente-les sous forme de liste num√©rot√©e de 1 √† 10.
                    """
                    
                    response = call_gpt4o_mini(prompt)
                    if response:
                        questions = extract_questions_from_response(response)
                        # S'assurer d'avoir exactement 10 questions
                        for question in questions[:10]:
                            all_questions_data.append({
                                'Mot-cl√©': keyword,
                                'Suggestion Google': suggestion,
                                'Question Conversationnelle': question
                            })
                    
                    processed += 1
                    progress_bar.progress(20 + (processed * 50 // total_items))
                    time.sleep(0.8)  # √âviter le rate limiting
                    
                    # Affichage du progr√®s en temps r√©el
                    current_questions = len(all_questions_data)
                    status_text.text(f"‚è≥ √âtape 2/4: {current_questions} questions g√©n√©r√©es...")
                
                if not all_questions_data:
                    st.error("‚ùå Aucune question g√©n√©r√©e")
                else:
                    st.info(f"‚úÖ {len(all_questions_data)} questions g√©n√©r√©es au total")
                    
                    # √âtape 3: Consolidation et d√©duplication
                    status_text.text("‚è≥ √âtape 3/4: Consolidation et d√©duplication...")
                    progress_bar.progress(80)
                    
                    # Utiliser la fonction de consolidation am√©lior√©e
                    final_consolidated_data = consolidate_and_deduplicate(
                        all_questions_data, 
                        final_questions_count
                    )
                    
                    progress_bar.progress(90)
                    
                    # √âtape 4: Pr√©paration des r√©sultats finaux
                    status_text.text("‚è≥ √âtape 4/4: Pr√©paration des r√©sultats...")
                    
                    progress_bar.progress(100)
                    status_text.text("‚úÖ Analyse termin√©e !")
                    
                    # Affichage des r√©sultats
                    with results_container:
                        st.markdown("## üìä R√©sultats de l'analyse")
                        
                        # M√©triques am√©lior√©es
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("Mots-cl√©s analys√©s", len(keywords))
                        with col2:
                            st.metric("Suggestions collect√©es", len(all_suggestions))
                        with col3:
                            st.metric("Questions g√©n√©r√©es", len(all_questions_data))
                        with col4:
                            st.metric("Questions finales", len(final_consolidated_data))
                        
                        # Tableau des r√©sultats avec tri par pertinence
                        st.markdown("### üìã Tableau des r√©sultats (par pertinence d√©croissante)")
                        
                        # Cr√©er le DataFrame avec les colonnes dans l'ordre demand√©
                        df_results = pd.DataFrame(final_consolidated_data)
                        
                        # R√©organiser les colonnes selon vos sp√©cifications
                        df_display = df_results[['Requ√™tes Conversationnelles', 'Suggestion', 'Mot-cl√©']].copy()
                        
                        st.dataframe(df_display, use_container_width=True)
                        
                        # Statistiques de consolidation
                        with st.expander("üìä Statistiques de consolidation"):
                            st.markdown(f"**Taux de consolidation:** {(len(all_questions_data) - len(final_consolidated_data)) / len(all_questions_data) * 100:.1f}%")
                            st.markdown(f"**Questions √©limin√©es:** {len(all_questions_data) - len(final_consolidated_data)}")
                            st.markdown(f"**Questions conserv√©es:** {len(final_consolidated_data)}")
                            
                            # Top mots-cl√©s
                            keyword_counts = df_results['Mot-cl√©'].value_counts()
                            st.markdown("**R√©partition par mot-cl√©:**")
                            for keyword, count in keyword_counts.items():
                                st.markdown(f"- {keyword}: {count} questions")
                        
                        # Visualisation am√©lior√©e
                        st.markdown("### üó∫Ô∏è R√©partition des r√©sultats")
                        
                        if len(final_consolidated_data) > 0:
                            try:
                                # Graphique en barres de la r√©partition par mot-cl√©
                                keyword_counts = df_results['Mot-cl√©'].value_counts()
                                
                                fig_bar = px.bar(
                                    x=keyword_counts.index,
                                    y=keyword_counts.values,
                                    title="R√©partition des questions par mot-cl√©",
                                    labels={'x': 'Mots-cl√©s', 'y': 'Nombre de questions'}
                                )
                                st.plotly_chart(fig_bar, use_container_width=True)
                                
                                # Graphique en secteurs
                                fig_pie = px.pie(
                                    values=keyword_counts.values,
                                    names=keyword_counts.index,
                                    title="Proportion des questions par mot-cl√©"
                                )
                                st.plotly_chart(fig_pie, use_container_width=True)
                                
                            except Exception as e:
                                st.warning(f"‚ö†Ô∏è Impossible d'afficher la visualisation: {str(e)}")
                        
                        # Export am√©lior√© des r√©sultats
                        st.markdown("### üì§ Export des r√©sultats")
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            # Export Excel
                            excel_file = create_excel_file(df_display)
                            st.download_button(
                                label="üìä T√©l√©charger Excel",
                                data=excel_file,
                                file_name="questions_conversationnelles_consolidees.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                            )
                        
                        with col2:
                            # Export JSON avec m√©tadonn√©es
                            export_json = {
                                "metadata": {
                                    "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                                    "keywords_analyzed": keywords,
                                    "total_questions_generated": len(all_questions_data),
                                    "final_questions_count": len(final_consolidated_data),
                                    "consolidation_rate": f"{(len(all_questions_data) - len(final_consolidated_data)) / len(all_questions_data) * 100:.1f}%"
                                },
                                "results": final_consolidated_data
                            }
                            
                            json_data = json.dumps(export_json, ensure_ascii=False, indent=2)
                            st.download_button(
                                label="üìã T√©l√©charger JSON",
                                data=json_data,
                                file_name="questions_conversationnelles_consolidees.json",
                                mime="application/json"
                            )

# Instructions d'utilisation
if not api_key:
    st.markdown("""
    ## üìñ Instructions d'utilisation
    
    ### üîç Processus d'analyse en 4 √©tapes
    
    1. **Configuration** : Entrez votre cl√© API OpenAI dans la barre lat√©rale
    2. **Saisie des mots-cl√©s** : Entrez vos mots-cl√©s (un par ligne)
    3. **Param√©trage** : Ajustez le nombre de suggestions et questions finales
    4. **Analyse** : Lancez l'analyse et obtenez vos questions conversationnelles
    
    ### ‚öôÔ∏è Fonctionnalit√©s principales:
    - **Collecte automatique** des suggestions Google r√©elles
    - **G√©n√©ration intelligente** de 10 questions par suggestion
    - **Consolidation avanc√©e** avec d√©duplication et scoring
    - **Export professionnel** en Excel et JSON
    
    ### üéØ Exemples de mots-cl√©s:
    - restaurant paris
    - formation d√©veloppement web
    - voyage √©cologique
    - coaching personnel
    - e-commerce bio
    
    ### üìä R√©sultats obtenus:
    - Questions conversationnelles optimis√©es SEO
    - Tri√©es par pertinence d√©croissante
    - Pr√™tes pour l'int√©gration dans votre contenu
    """)

# Footer
st.markdown("---")
st.markdown("*Outil d'optimisation SEO pour requ√™tes conversationnelles | Powered by GPT-4o mini & Streamlit*")
