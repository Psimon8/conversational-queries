import streamlit as st
from openai import OpenAI
import pandas as pd
import json
import time
from collections import Counter
import re
import requests
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.express as px
from io import BytesIO

# Import du module de g√©n√©ration de questions
from question_generator import QuestionGenerator

# Configuration de la page Streamlit
st.set_page_config(
    page_title="SEO Conversational Queries Optimizer",
    page_icon="üîç",
    layout="wide"
)

# Initialisation du session state
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = None
if 'analysis_metadata' not in st.session_state:
    st.session_state.analysis_metadata = None

# Titre principal
st.title("üîç Optimiseur de Requ√™tes Conversationnelles SEO")
st.subheader("Analyse bas√©e sur les suggestions Google pour l'optimisation SEO")

# Configuration dans la sidebar
st.sidebar.header("‚öôÔ∏è Configuration")
api_key = st.sidebar.text_input("Cl√© API OpenAI", type="password", help="Votre cl√© API OpenAI pour GPT-4o mini")

if api_key:
    client = OpenAI(api_key=api_key)
    st.sidebar.success("‚úÖ API configur√©e")
    # Initialiser le g√©n√©rateur de questions avec le client
    question_generator = QuestionGenerator(client)
else:
    st.sidebar.warning("‚ö†Ô∏è Veuillez entrer votre cl√© API OpenAI")
    client = None
    question_generator = QuestionGenerator()

# Options de g√©n√©ration dans la sidebar
st.sidebar.header("üéØ Options d'analyse")
generate_questions = st.sidebar.checkbox(
    "G√©n√©rer questions conversationnelles",
    value=True,
    help="G√©n√©rer des questions conversationnelles √† partir des suggestions"
)

if generate_questions:
    final_questions_count = st.sidebar.slider(
        "Nombre de questions finales",
        min_value=5,
        max_value=100,
        value=20,
        help="Nombre de questions conversationnelles √† conserver apr√®s consolidation"
    )

lang = st.sidebar.selectbox(
    "Langue", 
    ["fr", "en", "es", "de", "it"], 
    index=0,
    help="Langue pour les suggestions Google"
)

# Ajouter les liens sociaux en bas de la sidebar
st.sidebar.markdown(
    """
    <div style="position: fixed; bottom: 10px; left: 20px;">
        <a href="https://github.com/Psimon8" target="_blank" style="text-decoration: none;">
            <img src="https://github.githubassets.com/assets/pinned-octocat-093da3e6fa40.svg" 
                 alt="GitHub Simon le Coz" style="width:20px; vertical-align: middle; margin-right: 5px;">
            <span style="color: white; font-size: 14px;"></span>
        </a>    
        <a href="https://www.linkedin.com/in/simon-le-coz/" target="_blank" style="text-decoration: none;">
            <img src="https://static.licdn.com/aero-v1/sc/h/8s162nmbcnfkg7a0k8nq9wwqo" 
                 alt="LinkedIn Simon Le Coz" style="width:20px; vertical-align: middle; margin-right: 5px;">
            <span style="color: white; font-size: 14px;"></span>
        </a>
        <a href="https://twitter.com/lekoz_simon" target="_blank" style="text-decoration: none;">
            <img src="https://abs.twimg.com/favicons/twitter.3.ico" 
                 alt="Twitter Simon Le Coz" style="width:20px; vertical-align: middle; margin-right: 5px;">
            <span style="color: white; font-size: 14px;">@lekoz_simon</span>
        </a>
    </div>
    """,
    unsafe_allow_html=True
)

# Fonctions utilitaires pour les suggestions Google
def get_google_suggestions(keyword, lang='fr', max_suggestions=10):
    """R√©cup√®re les suggestions Google pour un mot-cl√©"""
    url = "https://suggestqueries.google.com/complete/search"
    params = {
        "q": keyword,
        "gl": lang,
        "client": "chrome",
        "_": str(int(time.time() * 1000))
    }
    
    try:
        response = requests.get(url, params=params, timeout=5)
        response.raise_for_status()
        suggestions = response.json()[1][:max_suggestions]
        return suggestions
    except Exception as e:
        st.error(f"‚ùå Erreur lors de la r√©cup√©ration des suggestions pour '{keyword}': {str(e)}")
        return []

def get_google_suggestions_multilevel(keyword, lang='fr', level1_count=10, level2_count=5, level3_count=0, enable_level2=True, enable_level3=False):
    """R√©cup√®re les suggestions Google √† plusieurs niveaux"""
    all_suggestions = []
    processed_suggestions = set()  # Pour √©viter les doublons
    
    # Ajouter le mot-cl√© de base (niveau 0)
    all_suggestions.append({
        'Mot-cl√©': keyword,
        'Niveau': 0,
        'Suggestion Google': keyword,
        'Parent': None
    })
    processed_suggestions.add(keyword.lower().strip())
    
    # Niveau 1: Suggestions directes du mot-cl√©
    level1_suggestions = get_google_suggestions(keyword, lang, level1_count)
    
    for suggestion in level1_suggestions:
        normalized = suggestion.lower().strip()
        if normalized not in processed_suggestions:
            all_suggestions.append({
                'Mot-cl√©': keyword,
                'Niveau': 1,
                'Suggestion Google': suggestion,
                'Parent': keyword
            })
            processed_suggestions.add(normalized)
    
    # Niveau 2: Suggestions des suggestions (si activ√©)
    if enable_level2:
        level2_parents = []
        for suggestion_data in all_suggestions.copy():  # Copie pour √©viter la modification pendant l'it√©ration
            if suggestion_data['Niveau'] == 1:  # Traiter uniquement les suggestions de niveau 1
                level2_suggestions = get_google_suggestions(suggestion_data['Suggestion Google'], lang, level2_count)
                
                for l2_suggestion in level2_suggestions:
                    normalized = l2_suggestion.lower().strip()
                    if normalized not in processed_suggestions:
                        new_suggestion = {
                            'Mot-cl√©': keyword,
                            'Niveau': 2,
                            'Suggestion Google': l2_suggestion,
                            'Parent': suggestion_data['Suggestion Google']
                        }
                        all_suggestions.append(new_suggestion)
                        level2_parents.append(new_suggestion)
                        processed_suggestions.add(normalized)
                
                time.sleep(0.3)  # D√©lai entre les requ√™tes pour √©viter le rate limiting
        
        # Niveau 3: Suggestions des suggestions de niveau 2 (si activ√©)
        if enable_level3:
            for suggestion_data in level2_parents:  # Traiter uniquement les suggestions de niveau 2
                level3_suggestions = get_google_suggestions(suggestion_data['Suggestion Google'], lang, level3_count)
                
                for l3_suggestion in level3_suggestions:
                    normalized = l3_suggestion.lower().strip()
                    if normalized not in processed_suggestions:
                        all_suggestions.append({
                            'Mot-cl√©': keyword,
                            'Niveau': 3,
                            'Suggestion Google': l3_suggestion,
                            'Parent': suggestion_data['Suggestion Google']
                        })
                        processed_suggestions.add(normalized)
                
                time.sleep(0.3)  # D√©lai entre les requ√™tes pour √©viter le rate limiting
    
    return all_suggestions

def consolidate_and_deduplicate(questions_data, target_count):
    """Consolide et d√©duplique les questions en gardant les plus pertinentes"""
    if not questions_data:
        return []
    
    # Cr√©er un dictionnaire pour comptabiliser les occurrences et garder les m√©tadonn√©es
    question_stats = {}
    
    for item in questions_data:
        question = item['Question Conversationnelle'].strip()
        # Normalisation pour d√©tecter les similitudes
        normalized = re.sub(r'[^\w\s]', '', question.lower()).strip()
        
        if normalized not in question_stats:
            question_stats[normalized] = {
                'original_question': question,
                'count': 1,
                'suggestions': [item['Suggestion Google']],
                'keywords': [item['Mot-cl√©']],
                'first_occurrence': item
            }
        else:
            question_stats[normalized]['count'] += 1
            if item['Suggestion Google'] not in question_stats[normalized]['suggestions']:
                question_stats[normalized]['suggestions'].append(item['Suggestion Google'])
            if item['Mot-cl√©'] not in question_stats[normalized]['keywords']:
                question_stats[normalized]['keywords'].append(item['Mot-cl√©'])
    
    # Trier par nombre d'occurrences (pertinence) et prendre les meilleures
    sorted_questions = sorted(
        question_stats.values(),
        key=lambda x: (x['count'], len(x['keywords'])),
        reverse=True
    )
    
    # Prendre le nombre demand√© de questions
    final_questions = []
    for i, q_data in enumerate(sorted_questions[:target_count]):
        final_questions.append({
            'Requ√™tes Conversationnelles': q_data['original_question'],
            'Suggestion': q_data['suggestions'][0],  # Premi√®re suggestion associ√©e
            'Mot-cl√©': q_data['keywords'][0],  # Premier mot-cl√© associ√©
            'Score_Pertinence': q_data['count'],
            'Nb_Keywords': len(q_data['keywords']),
            'Nb_Suggestions': len(q_data['suggestions'])
        })
    
    return final_questions

def create_excel_file(df):
    """Cr√©e un fichier Excel avec formatage"""
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='Questions_Conversationnelles')
        
        # Acc√©der au workbook et worksheet pour le formatage
        workbook = writer.book
        worksheet = writer.sheets['Questions_Conversationnelles']
        
        # Ajuster la largeur des colonnes
        worksheet.column_dimensions['A'].width = 60  # Questions
        worksheet.column_dimensions['B'].width = 50  # Suggestions Google
        worksheet.column_dimensions['C'].width = 25  # Mots-cl√©s
        worksheet.column_dimensions['D'].width = 25  # Th√®me
        worksheet.column_dimensions['E'].width = 20  # Intention
        worksheet.column_dimensions['F'].width = 15  # Importance
        
        # Formatage de l'en-t√™te
        from openpyxl.styles import Font, PatternFill
        header_font = Font(bold=True)
        header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
        
        for cell in worksheet[1]:
            cell.font = header_font
            cell.fill = header_fill
    
    output.seek(0)
    return output

# Export des r√©sultats dans la sidebar (apr√®s la d√©finition des fonctions)
if 'analysis_results' in st.session_state and st.session_state.analysis_results is not None:
    results = st.session_state.analysis_results
    metadata = st.session_state.analysis_metadata
    
    st.sidebar.header("üì§ Export des r√©sultats")
    
    # V√©rifier que les questions ont √©t√© g√©n√©r√©es avant d'afficher les exports
    if (metadata['generate_questions'] and 
        results.get('stage') == 'questions_generated' and 
        results.get('final_consolidated_data') and 
        len(results['final_consolidated_data']) > 0):
        
        # Export Excel des questions avec th√®mes et suggestions
        excel_df = pd.DataFrame(results['final_consolidated_data'])
        excel_display = excel_df[['Question Conversationnelle', 'Suggestion Google', 'Mot-cl√©', 'Th√®me', 'Intention', 'Score_Importance']].copy()
        excel_display.columns = ['Questions Conversationnelles', 'Suggestion Google', 'Mot-cl√©', 'Th√®me', 'Intention', 'Importance']
        
        excel_file = create_excel_file(excel_display)
        st.sidebar.download_button(
            label="üìä Questions (Excel)",
            data=excel_file,
            file_name="questions_conversationnelles_themes.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key="download_questions_themes_excel",
            use_container_width=True
        )
    
    # Export Excel des suggestions (toujours disponible apr√®s analyse)
    if results.get('all_suggestions') and len(results['all_suggestions']) > 0:
        suggestions_df = pd.DataFrame(results['all_suggestions'])
        suggestions_display = suggestions_df[['Mot-cl√©', 'Suggestion Google', 'Niveau', 'Parent']].copy()
        suggestions_excel = create_excel_file(suggestions_display)
        st.sidebar.download_button(
            label="üîç Suggestions (Excel)",
            data=suggestions_excel,
            file_name="suggestions_google_multiniveaux.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key="download_suggestions_excel",
            use_container_width=True
        )
    
    # Export JSON complet (adapt√© selon l'√©tape)
    if results.get('all_suggestions'):
        export_json = {
            "metadata": {
                **metadata,
                "total_suggestions": len(results.get('all_suggestions', [])),
                "level_distribution": results.get('level_counts', {}),
                "stage": results.get('stage', 'unknown')
            },
            "suggestions": results.get('all_suggestions', []),
            "themes_analysis": results.get('themes_analysis', {}),
            "questions": results.get('final_consolidated_data', []) if metadata.get('generate_questions') and results.get('stage') == 'questions_generated' else []
        }
        
        json_data = json.dumps(export_json, ensure_ascii=False, indent=2)
        st.sidebar.download_button(
            label="üìã Donn√©es (JSON)",
            data=json_data,
            file_name="analyse_complete_multiniveaux.json",
            mime="application/json",
            key="download_json",
            use_container_width=True
        )
    
    # Afficher l'√©tat actuel dans la sidebar
    if results.get('stage') == 'themes_analyzed' and metadata.get('generate_questions'):
        st.sidebar.info("üìã S√©lectionnez vos th√®mes pour g√©n√©rer les questions")
    elif results.get('stage') == 'questions_generated':
        st.sidebar.success("‚úÖ Questions g√©n√©r√©es - Exports disponibles")
    elif results.get('all_suggestions'):
        st.sidebar.success("‚úÖ Suggestions collect√©es - Export disponible")

def analyze_suggestion_relevance(keyword, suggestion, level):
    """Analyse la pertinence d'une suggestion par rapport au mot-cl√© principal"""
    if not client:
        return {"category": "unknown", "relevance_score": 0, "intent": "unknown"}
    
    prompt = f"""
    Analyse la suggestion Google "{suggestion}" (niveau {level}) par rapport au mot-cl√© principal "{keyword}".
    
    √âvalue selon ces crit√®res :
    1. PERTINENCE (0-10) : √Ä quel point la suggestion est-elle li√©e au mot-cl√© principal ?
    2. CAT√âGORIE : Classe la suggestion dans une de ces cat√©gories :
       - "core" : Directement li√© au mot-cl√© principal
       - "related" : Li√© mais avec une nuance diff√©rente
       - "complementary" : Compl√©mentaire ou service associ√©
       - "geographic" : Variation g√©ographique
       - "temporal" : Variation temporelle (horaires, saisons...)
       - "competitive" : Comparaison ou alternative
       - "informational" : Recherche d'information
       - "transactional" : Intention d'achat/r√©servation
       - "navigational" : Recherche d'un lieu/site sp√©cifique
    
    3. INTENTION : D√©termine l'intention de recherche :
       - "informational" : Cherche de l'information
       - "navigational" : Cherche √† aller quelque part
       - "transactional" : Veut acheter/r√©server
       - "local" : Recherche locale
    
    R√©ponds UNIQUEMENT au format JSON :
    {{"relevance_score": X, "category": "xxx", "intent": "xxx", "justification": "courte explication"}}
    """
    
    try:
        response = call_gpt4o_mini(prompt)
        if response:
            # Nettoyer la r√©ponse pour extraire le JSON
            response_clean = response.strip()
            if response_clean.startswith('```json'):
                response_clean = response_clean[7:-3]
            elif response_clean.startswith('```'):
                response_clean = response_clean[3:-3]
            
            return json.loads(response_clean)
    except Exception as e:
        st.warning(f"Erreur analyse suggestion '{suggestion}': {str(e)}")
    
    # Fallback basique si l'analyse GPT √©choue
    return {
        "relevance_score": 5, 
        "category": "related", 
        "intent": "informational",
        "justification": "Analyse automatique indisponible"
    }

def generate_contextual_questions(keyword, suggestion, analysis_data, num_questions=3):
    """G√©n√®re des questions conversationnelles contextuelles bas√©es sur l'analyse"""
    if not client:
        return []
    
    category = analysis_data.get('category', 'related')
    intent = analysis_data.get('intent', 'informational')
    relevance = analysis_data.get('relevance_score', 5)
    
    # Adapter le prompt selon la cat√©gorie et l'intention
    context_prompts = {
        "core": "questions directement li√©es au c≈ìur du sujet",
        "related": "questions sur les aspects connexes",
        "complementary": "questions sur les services/produits compl√©mentaires",
        "geographic": "questions g√©olocalis√©es",
        "temporal": "questions temporelles (quand, horaires, saisons)",
        "competitive": "questions de comparaison",
        "informational": "questions d'information pratique",
        "transactional": "questions d'achat/r√©servation",
        "navigational": "questions de localisation/acc√®s"
    }
    
    intent_focus = {
        "informational": "Concentre-toi sur des questions 'comment', 'pourquoi', 'qu'est-ce que'",
        "navigational": "Concentre-toi sur des questions 'o√π', 'comment acc√©der', 'comment trouver'",
        "transactional": "Concentre-toi sur des questions 'combien', 'comment acheter/r√©server', 'quelles options'",
        "local": "Concentre-toi sur des questions g√©olocalis√©es 'pr√®s de moi', 'dans ma r√©gion'"
    }
    
    prompt = f"""
    Mot-cl√© principal : "{keyword}"
    Suggestion analys√©e : "{suggestion}"
    Cat√©gorie : {category} ({context_prompts.get(category, 'questions g√©n√©rales')})
    Intention : {intent} ({intent_focus.get(intent, 'questions g√©n√©rales')})
    Score de pertinence : {relevance}/10
    
    G√©n√®re EXACTEMENT {num_questions} questions conversationnelles SEO optimis√©es qui :
    Sont adapt√©es √† la cat√©gorie "{category}" et l'intention "{intent}"
    Int√®grent naturellement le contexte de la suggestion
    Sont formul√©es comme des questions que les utilisateurs poseraient vraiment
    Sont optimis√©es pour la recherche vocale
    Se terminent par un point d'interrogation
    Sont de longueur appropri√©e (ni trop courtes, ni trop longues)
    
    Exemples de formulations selon l'intention :
    - Informational : "Comment...", "Pourquoi...", "Qu'est-ce que..."
    - Transactional : "Combien co√ªte...", "O√π acheter...", "Comment r√©server..."
    - Local : "O√π trouver... pr√®s de moi", "Quel est le meilleur... dans ma ville"
    
    Pr√©sente les questions sous forme de liste num√©rot√©e de 1 √† {num_questions}.
    """
    
    response = call_gpt4o_mini(prompt)
    if response:
        return extract_questions_from_response(response)
    return []

def smart_question_generation(all_suggestions_with_analysis, target_questions):
    """G√©n√®re intelligemment les questions en fonction de l'analyse des suggestions"""
    if not all_suggestions_with_analysis:
        return []
    
    # Trier les suggestions par pertinence d√©croissante
    sorted_suggestions = sorted(
        all_suggestions_with_analysis, 
        key=lambda x: x.get('analysis', {}).get('relevance_score', 0), 
        reverse=True
    )
    
    # Grouper par cat√©gorie et intention pour √©quilibrer
    categories = {}
    for suggestion in sorted_suggestions:
        analysis = suggestion.get('analysis', {})
        category = analysis.get('category', 'unknown')
        
        if category not in categories:
            categories[category] = []
        categories[category].append(suggestion)
    
    # Calculer la distribution des questions par cat√©gorie
    total_suggestions = len(sorted_suggestions)
    questions_per_suggestion = max(1, target_questions // total_suggestions)
    
    all_generated_questions = []
    questions_generated = 0
    
    # Prioriser les cat√©gories les plus pertinentes
    priority_categories = ['core', 'transactional', 'informational', 'related', 'complementary']
    
    for category in priority_categories:
        if category in categories and questions_generated < target_questions:
            category_suggestions = categories[category][:3]  # Max 3 suggestions par cat√©gorie
            
            for suggestion_data in category_suggestions:
                if questions_generated >= target_questions:
                    break
                
                # Calculer le nombre de questions pour cette suggestion
                remaining_questions = target_questions - questions_generated
                analysis = suggestion_data.get('analysis', {})
                relevance = analysis.get('relevance_score', 5)
                
                # Plus la suggestion est pertinente, plus on g√©n√®re de questions
                if relevance >= 8:
                    num_questions = min(5, remaining_questions)
                elif relevance >= 6:
                    num_questions = min(3, remaining_questions)
                else:
                    num_questions = min(2, remaining_questions)
                
                if num_questions > 0:
                    questions = generate_contextual_questions(
                        suggestion_data['Mot-cl√©'],
                        suggestion_data['Suggestion Google'],
                        analysis,
                        num_questions
                    )
                    
                    for question in questions:
                        if questions_generated < target_questions:
                            all_generated_questions.append({
                                'Mot-cl√©': suggestion_data['Mot-cl√©'],
                                'Suggestion Google': suggestion_data['Suggestion Google'],
                                'Question Conversationnelle': question,
                                'Niveau': suggestion_data['Niveau'],
                                'Parent': suggestion_data['Parent'],
                                'Cat√©gorie': category,
                                'Intention': analysis.get('intent', 'unknown'),
                                'Score_Pertinence': relevance
                            })
                            questions_generated += 1
    
    # Compl√©ter avec les cat√©gories restantes si n√©cessaire
    for category, suggestions in categories.items():
        if category not in priority_categories and questions_generated < target_questions:
            for suggestion_data in suggestions:
                if questions_generated >= target_questions:
                    break
                
                remaining_questions = target_questions - questions_generated
                questions = generate_contextual_questions(
                    suggestion_data['Mot-cl√©'],
                    suggestion_data['Suggestion Google'],
                    suggestion_data.get('analysis', {}),
                    min(2, remaining_questions)
                )
                
                for question in questions:
                    if questions_generated < target_questions:
                        analysis = suggestion_data.get('analysis', {})
                        all_generated_questions.append({
                            'Mot-cl√©': suggestion_data['Mot-cl√©'],
                            'Suggestion Google': suggestion_data['Suggestion Google'],
                            'Question Conversationnelle': question,
                            'Niveau': suggestion_data['Niveau'],
                            'Parent': suggestion_data['Parent'],
                            'Cat√©gorie': category,
                            'Intention': analysis.get('intent', 'unknown'),
                            'Score_Pertinence': analysis.get('relevance_score', 5)
                        })
                        questions_generated += 1
    
    return all_generated_questions

def analyze_suggestions_themes(all_suggestions, keyword):
    """Analyse les suggestions pour identifier les th√®mes r√©currents"""
    if not client or not all_suggestions:
        return []
    
    # Cr√©er une liste des suggestions sans doublons pour analyse
    suggestions_text = []
    for item in all_suggestions:
        if item['Niveau'] > 0:  # Exclure le mot-cl√© de base
            suggestions_text.append(item['Suggestion Google'])
    
    # Limiter √† 50 suggestions max pour l'analyse
    suggestions_sample = list(set(suggestions_text))[:50]
    
    if not suggestions_sample:
        return []
    
    prompt = f"""
    Analyse ces suggestions Google pour le mot-cl√© principal "{keyword}" et identifie les th√®mes r√©currents :
    
    Suggestions √† analyser :
    {chr(10).join([f"- {s}" for s in suggestions_sample])}
    
    Identifie les 5-10 TH√àMES PRINCIPAUX qui ressortent de ces suggestions.
    Pour chaque th√®me, indique :
    1. Le nom du th√®me
    2. Les mots-cl√©s/concepts r√©currents
    3. L'intention de recherche dominante
    4. Le niveau d'importance (1-5)
    
    R√©ponds UNIQUEMENT au format JSON :
    {{
        "themes": [
            {{
                "nom": "nom_du_theme",
                "concepts": ["concept1", "concept2"],
                "intention": "informational",
                "importance": 4,
                "exemples_suggestions": ["suggestion1", "suggestion2"]
            }}
        ]
    }}
    """
    
    try:
        response = call_gpt4o_mini(prompt)
        if response:
            response_clean = response.strip()
            if response_clean.startswith('```json'):
                response_clean = response_clean[7:-3]
            elif response_clean.startswith('```'):
                response_clean = response_clean[3:-3]
            
            parsed = json.loads(response_clean)
            return parsed.get('themes', [])
    except Exception as e:
        st.warning(f"Erreur analyse th√®mes pour '{keyword}': {str(e)}")
        return []

def generate_questions_from_themes(keyword, themes, target_count):
    """G√©n√®re des questions conversationnelles bas√©es sur les th√®mes identifi√©s"""
    if not client or not themes or target_count <= 0:
        return []
    
    # Trier les th√®mes par importance
    sorted_themes = sorted(themes, key=lambda x: x.get('importance', 0), reverse=True)
    
    # Calculer la r√©partition des questions par th√®me
    questions_per_theme = max(1, target_count // len(sorted_themes))
    remaining_questions = target_count
    
    all_questions = []
    
    for i, theme in enumerate(sorted_themes):
        if remaining_questions <= 0:
            break
        
        # Calculer le nombre de questions pour ce th√®me
        if i == len(sorted_themes) - 1:  # Dernier th√®me
            theme_questions = remaining_questions
        else:
            theme_questions = min(questions_per_theme, remaining_questions)
        
        if theme_questions > 0:
            theme_name = theme.get('nom', 'theme')
            concepts = ', '.join(theme.get('concepts', []))
            intention = theme.get('intention', 'informational')
            exemples = ', '.join(theme.get('exemples_suggestions', [])[:3])
            
            prompt = f"""
            G√©n√®re EXACTEMENT {theme_questions} questions conversationnelles SEO pour :
            
            Mot-cl√© principal : "{keyword}"
            Th√®me : "{theme_name}"
            Concepts cl√©s : {concepts}
            Intention : {intention}
            Exemples de suggestions : {exemples}
            
            Les questions doivent :
            1. √ätre naturelles et conversationnelles
            2. Int√©grer le th√®me "{theme_name}" de mani√®re naturelle
            3. Correspondre √† l'intention "{intention}"
            4. √ätre optimis√©es pour la recherche vocale
            5. Se terminer par un point d'interrogation
            6. √ätre vari√©es et compl√©mentaires
            
            Formulations selon l'intention :
            - Informational : "Comment...", "Pourquoi...", "Qu'est-ce que...", "Quels sont..."
            - Transactional : "Combien co√ªte...", "O√π acheter...", "Comment r√©server...", "Quel prix..."
            - Navigational : "O√π trouver...", "Comment acc√©der...", "Quelle adresse..."
            - Local : "... pr√®s de moi", "... dans ma ville", "... dans ma r√©gion"
            
            Pr√©sente les questions sous forme de liste num√©rot√©e de 1 √† {theme_questions}.
            """
            
            response = call_gpt4o_mini(prompt)
            if response:
                theme_questions_list = extract_questions_from_response(response)
                for question in theme_questions_list[:theme_questions]:
                    all_questions.append({
                        'Question Conversationnelle': question,
                        'Th√®me': theme_name,
                        'Intention': intention,
                        'Concepts': concepts,
                        'Score_Importance': theme.get('importance', 3)
                    })
                    remaining_questions -= 1
    
    return all_questions

# Cr√©ation des onglets
tab1, tab2 = st.tabs(["üîç Analyseur de Requ√™tes", "üìñ Instructions"])

# TAB 1: Analyseur principal
with tab1:
    # Interface principale - Analyse par Suggestions Google
    st.markdown("### üîç Analyse bas√©e sur les suggestions Google multi-niveaux")
    
    # Input pour les mots-cl√©s
    keywords_input = st.text_area(
        "üéØ Entrez vos mots-cl√©s (un par ligne)",
        placeholder="restaurant paris\nh√¥tel luxe\nvoyage √©cologique",
        help="Entrez un ou plusieurs mots-cl√©s, un par ligne"
    )
    
    # Configuration des niveaux de suggestions
    st.markdown("#### üìä Configuration des niveaux de suggestions")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        level1_count = st.slider(
            "Suggestions niveau 1", 
            min_value=2, 
            max_value=15, 
            value=10,
            help="Nombre de suggestions Google directes pour chaque mot-cl√©"
        )
    
    with col2:
        level2_count = st.slider(
            "Suggestions niveau 2", 
            min_value=0,
            max_value=15, 
            value=0,
            help="Nombre de suggestions pour chaque suggestion de niveau 1 (0 = d√©sactiv√©)"
        )
    
    with col3:
        level3_count = st.slider(
            "Suggestions niveau 3", 
            min_value=0,
            max_value=15, 
            value=0,
            help="Nombre de suggestions pour chaque suggestion de niveau 2 (0 = d√©sactiv√©)"
        )
    
    # Boutons d'action
    col_analyze, col_clear = st.columns([4, 1])
    with col_analyze:
        if keywords_input:
            if generate_questions and not api_key:
                st.warning("‚ö†Ô∏è Veuillez configurer votre cl√© API OpenAI dans la barre lat√©rale pour g√©n√©rer les questions conversationnelles.")
            elif keywords_input:
                keywords = [kw.strip() for kw in keywords_input.split('\n') if kw.strip()]
                
                # √âtape 1: Analyse des suggestions et th√®mes
                if st.button("üöÄ Analyser les suggestions", type="primary"):
                    if not keywords:
                        st.error("‚ùå Veuillez entrer au moins un mot-cl√©")
                    else:
                        # R√©initialiser les r√©sultats pr√©c√©dents
                        st.session_state.analysis_results = None
                        st.session_state.analysis_metadata = None
                        st.session_state.themes_selection = None
                        
                        try:
                            # Progress tracking
                            progress_bar = st.progress(0)
                            status_text = st.empty()
                            
                            # D√©terminer les niveaux activ√©s
                            enable_level2 = level2_count > 0
                            enable_level3 = level3_count > 0 and enable_level2
                            
                            # √âtape 1: Collecte des suggestions multi-niveaux
                            status_text.text("‚è≥ √âtape 1/3: Collecte des suggestions Google multi-niveaux...")
                            
                            all_suggestions = []
                            
                            for i, keyword in enumerate(keywords):
                                keyword_suggestions = get_google_suggestions_multilevel(
                                    keyword, 
                                    lang, 
                                    level1_count, 
                                    level2_count, 
                                    level3_count,
                                    enable_level2,
                                    enable_level3
                                )
                                all_suggestions.extend(keyword_suggestions)
                                
                                progress_bar.progress((i + 1) * 30 // len(keywords))
                                status_text.text(f"‚è≥ Collecte en cours... {len(all_suggestions)} suggestions trouv√©es")
                            
                            if not all_suggestions:
                                st.error("‚ùå Aucune suggestion trouv√©e")
                            else:
                                # Affichage des statistiques de collecte
                                level_counts = {}
                                for suggestion in all_suggestions:
                                    level = suggestion['Niveau']
                                    level_counts[level] = level_counts.get(level, 0) + 1
                                
                                st.info(f"‚úÖ {len(all_suggestions)} suggestions collect√©es - Niveau 0: {level_counts.get(0, 0)}, Niveau 1: {level_counts.get(1, 0)}, Niveau 2: {level_counts.get(2, 0)}, Niveau 3: {level_counts.get(3, 0)}")
                                
                                all_themes = {}
                                
                                if generate_questions:
                                    # √âtape 2: Analyse des th√®mes r√©currents
                                    status_text.text("‚è≥ √âtape 2/3: Analyse des th√®mes r√©currents dans les suggestions...")
                                    progress_bar.progress(60)
                                    
                                    # Analyser les th√®mes pour chaque mot-cl√© avec le g√©n√©rateur ET la langue
                                    for i, keyword in enumerate(keywords):
                                        keyword_suggestions = [s for s in all_suggestions if s['Mot-cl√©'] == keyword]
                                        themes = question_generator.analyze_suggestions_themes(keyword_suggestions, keyword, lang)
                                        all_themes[keyword] = themes
                                        
                                        progress_bar.progress(60 + (i + 1) * 30 // len(keywords))
                                        time.sleep(1)  # D√©lai pour √©viter le rate limiting
                                    
                                    progress_bar.progress(90)
                                    status_text.text("‚è≥ √âtape 3/3: Finalisation de l'analyse...")
                                
                                progress_bar.progress(100)
                                status_text.text("‚úÖ Analyse des th√®mes termin√©e !")
                                
                                # Sauvegarder les r√©sultats interm√©diaires
                                st.session_state.analysis_results = {
                                    'all_suggestions': all_suggestions,
                                    'level_counts': level_counts,
                                    'themes_analysis': all_themes if generate_questions else {},
                                    'stage': 'themes_analyzed'  # Nouveau flag pour indiquer l'√©tape
                                }
                                
                                st.session_state.analysis_metadata = {
                                    'keywords': keywords,
                                    'level1_count': level1_count,
                                    'level2_count': level2_count,
                                    'level3_count': level3_count,
                                    'enable_level2': enable_level2,
                                    'enable_level3': enable_level3,
                                    'generate_questions': generate_questions,
                                    'final_questions_count': final_questions_count if generate_questions else 0,
                                    'timestamp': time.strftime("%Y-%m-%d %H:%M:%S"),
                                    'language': lang
                                }
                                
                                # Nettoyer les √©l√©ments temporaires
                                progress_bar.empty()
                                status_text.empty()
                                
                                # Forcer le rechargement pour afficher l'interface de s√©lection
                                st.rerun()
                        
                        except Exception as e:
                            st.error(f"‚ùå Erreur lors de l'analyse: {str(e)}")

    with col_clear:
        if st.button("üóëÔ∏è Effacer", help="Effacer les r√©sultats actuels"):
            st.session_state.analysis_results = None
            st.session_state.analysis_metadata = None
            st.session_state.themes_selection = None
            st.rerun()
    
    # Interface de s√©lection des th√®mes (nouvelle section)
    if (st.session_state.get('analysis_results') is not None and 
        st.session_state.analysis_results.get('stage') == 'themes_analyzed' and
        st.session_state.analysis_metadata['generate_questions']):
        
        st.markdown("---")
        st.markdown("## üé® S√©lection des th√®mes pour la g√©n√©ration de questions")
        
        themes_analysis = st.session_state.analysis_results.get('themes_analysis', {})
        
        if themes_analysis:
            # Cr√©er une interface de s√©lection pour chaque mot-cl√©
            selected_themes_by_keyword = {}
            
            for keyword, themes in themes_analysis.items():
                if themes:
                    st.markdown(f"### üéØ Th√®mes identifi√©s pour '{keyword}'")
                    
                    # Cr√©er des colonnes pour l'affichage des th√®mes
                    themes_per_row = 2
                    for i in range(0, len(themes), themes_per_row):
                        cols = st.columns(themes_per_row)
                        
                        for j, theme in enumerate(themes[i:i+themes_per_row]):
                            with cols[j]:
                                theme_name = theme.get('nom', f'Th√®me {i+j+1}')
                                theme_importance = theme.get('importance', 3)
                                theme_intention = theme.get('intention', 'informational')
                                concepts = theme.get('concepts', [])
                                exemples = theme.get('exemples_suggestions', [])
                                
                                # Checkbox pour s√©lectionner le th√®me (s√©lectionn√© par d√©faut)
                                theme_key = f"{keyword}_{theme_name}_{i+j}"
                                is_selected = st.checkbox(
                                    f"**{theme_name}**",
                                    value=True,  # S√©lectionn√© par d√©faut
                                    key=theme_key,
                                    help=f"Importance: {theme_importance}/5 | Intention: {theme_intention}"
                                )
                                
                                if is_selected:
                                    if keyword not in selected_themes_by_keyword:
                                        selected_themes_by_keyword[keyword] = []
                                    selected_themes_by_keyword[keyword].append(theme)
                                
                                # Afficher les d√©tails du th√®me
                                with st.expander(f"D√©tails du th√®me '{theme_name}'"):
                                    st.write(f"**Importance:** {theme_importance}/5")
                                    st.write(f"**Intention:** {theme_intention}")
                                    if concepts:
                                        st.write(f"**Concepts:** {', '.join(concepts[:5])}")
                                    if exemples:
                                        st.write(f"**Exemples de suggestions:** {', '.join(exemples[:3])}")
            
            # Bouton pour g√©n√©rer les questions avec les th√®mes s√©lectionn√©s
            st.markdown("---")
            col_generate, col_info = st.columns([3, 2])
            
            with col_generate:
                total_selected_themes = sum(len(themes) for themes in selected_themes_by_keyword.values())
                
                if total_selected_themes > 0:
                    if st.button("‚ú® G√©n√©rer les questions avec les th√®mes s√©lectionn√©s", type="primary"):
                        # Lancer la g√©n√©ration avec les th√®mes s√©lectionn√©s
                        try:
                            progress_bar = st.progress(0)
                            status_text = st.empty()
                            
                            status_text.text("‚è≥ G√©n√©ration des questions conversationnelles...")
                            
                            metadata = st.session_state.analysis_metadata
                            final_questions_count = metadata['final_questions_count']
                            lang = metadata['language']
                            
                            all_questions_data = []
                            questions_per_keyword = final_questions_count // len(selected_themes_by_keyword)
                            remaining_questions = final_questions_count
                            
                            keyword_list = list(selected_themes_by_keyword.keys())
                            
                            for i, (keyword, selected_themes) in enumerate(selected_themes_by_keyword.items()):
                                if remaining_questions <= 0:
                                    break
                                
                                # Calculer le nombre de questions pour ce mot-cl√©
                                if i == len(keyword_list) - 1:  # Dernier mot-cl√©
                                    keyword_questions = remaining_questions
                                else:
                                    keyword_questions = min(questions_per_keyword, remaining_questions)
                                
                                if keyword_questions > 0 and selected_themes:
                                    keyword_questions_list = question_generator.generate_questions_from_themes(
                                        keyword, 
                                        selected_themes, 
                                        keyword_questions,
                                        lang
                                    )
                                    
                                    for q in keyword_questions_list:
                                        q['Mot-cl√©'] = keyword
                                        # Ajouter une suggestion Google repr√©sentative du th√®me
                                        theme_name = q.get('Th√®me', '')
                                        # Trouver une suggestion repr√©sentative du th√®me dans les suggestions collect√©es
                                        representative_suggestion = keyword  # Fallback
                                        if theme_name and selected_themes:
                                            for theme in selected_themes:
                                                if theme.get('nom') == theme_name:
                                                    exemples_suggestions = theme.get('exemples_suggestions', [])
                                                    if exemples_suggestions:
                                                        representative_suggestion = exemples_suggestions[0]
                                                    break
                                        q['Suggestion Google'] = representative_suggestion
                                        all_questions_data.append(q)
                                    
                                    remaining_questions -= len(keyword_questions_list)
                                
                                progress_bar.progress((i + 1) / len(keyword_list))
                                time.sleep(0.5)
                            
                            if all_questions_data:
                                # Trier par score d'importance et limiter au nombre demand√©
                                sorted_questions = sorted(
                                    all_questions_data,
                                    key=lambda x: x.get('Score_Importance', 0),
                                    reverse=True
                                )
                                
                                final_consolidated_data = sorted_questions[:final_questions_count]
                                
                                # Mettre √† jour les r√©sultats
                                st.session_state.analysis_results.update({
                                    'all_questions_data': all_questions_data,
                                    'final_consolidated_data': final_consolidated_data,
                                    'selected_themes_by_keyword': selected_themes_by_keyword,
                                    'stage': 'questions_generated'
                                })
                                
                                progress_bar.progress(1.0)
                                status_text.text(f"‚úÖ {len(final_consolidated_data)} questions g√©n√©r√©es avec succ√®s !")
                                
                                time.sleep(1)
                                progress_bar.empty()
                                status_text.empty()
                                
                                st.success(f"üéâ {len(final_consolidated_data)} questions conversationnelles g√©n√©r√©es √† partir de {total_selected_themes} th√®mes s√©lectionn√©s !")
                                
                                # Forcer le rechargement pour afficher les r√©sultats
                                st.rerun()
                            else:
                                st.error("‚ùå Aucune question g√©n√©r√©e")
                                
                        except Exception as e:
                            st.error(f"‚ùå Erreur lors de la g√©n√©ration: {str(e)}")
                else:
                    st.warning("‚ö†Ô∏è Veuillez s√©lectionner au moins un th√®me pour g√©n√©rer les questions.")
            
            with col_info:
                st.info(f"üìä **{total_selected_themes}** th√®mes s√©lectionn√©s sur {sum(len(themes) for themes in themes_analysis.values())}")
                if total_selected_themes > 0:
                    estimated_questions = min(final_questions_count, total_selected_themes * 3)
                    st.info(f"üéØ Environ **{estimated_questions}** questions seront g√©n√©r√©es")
        else:
            st.warning("‚ö†Ô∏è Aucun th√®me identifi√©. Relancez l'analyse avec d'autres mots-cl√©s.")
    
    # Affichage des r√©sultats finaux (existant, mais modifi√©)
    if (st.session_state.get('analysis_results') is not None and 
        st.session_state.analysis_results.get('stage') == 'questions_generated'):
        
        results = st.session_state.analysis_results
        metadata = st.session_state.analysis_metadata
        
        st.markdown("---")
        st.markdown("## üìä R√©sultats de l'analyse")
        
        # M√©triques avec questions
        col1, col2, col3, col4, col5 = st.columns(5)
        with col1:
            st.metric("Mots-cl√©s analys√©s", len(metadata['keywords']))
        with col2:
            st.metric("Suggestions collect√©es", len(results['all_suggestions']))
        with col3:
            total_themes_selected = sum(len(themes) for themes in results.get('selected_themes_by_keyword', {}).values())
            st.metric("Th√®mes s√©lectionn√©s", total_themes_selected)
        with col4:
            st.metric("Questions g√©n√©r√©es", len(results['final_consolidated_data']))
        with col5:
            avg_importance = sum(q.get('Score_Importance', 0) for q in results['final_consolidated_data']) / len(results['final_consolidated_data']) if results['final_consolidated_data'] else 0
            st.metric("Importance moyenne", f"{avg_importance:.1f}/5")
        
        # Tableau des suggestions par niveau
        st.markdown("### üîç Suggestions collect√©es par niveau")
        
        # Cr√©er un DataFrame pour les suggestions
        suggestions_df = pd.DataFrame(results['all_suggestions'])
        suggestions_display = suggestions_df[['Mot-cl√©', 'Suggestion Google', 'Niveau', 'Parent']].copy()
        
        # Filtres par niveau
        available_levels = suggestions_df['Niveau'].unique().tolist()
        nivel_filter = st.multiselect(
            "Filtrer par niveau",
            options=available_levels,
            default=available_levels,
            format_func=lambda x: f"Niveau {x}"
        )
        
        if nivel_filter:
            filtered_suggestions = suggestions_display[suggestions_display['Niveau'].isin(nivel_filter)]
            st.dataframe(filtered_suggestions, use_container_width=True)
        
        # Tableau des questions conversationnelles
        if len(results['final_consolidated_data']) > 0:
            st.markdown("### üìã Questions conversationnelles bas√©es sur les th√®mes s√©lectionn√©s")
            df_results = pd.DataFrame(results['final_consolidated_data'])
            df_display = df_results[['Question Conversationnelle', 'Suggestion Google', 'Th√®me', 'Intention', 'Score_Importance', 'Mot-cl√©']].copy()
            df_display.columns = ['Questions Conversationnelles', 'Suggestion Google', 'Th√®me', 'Intention', 'Importance', 'Mot-cl√©']
            st.dataframe(df_display, use_container_width=True)
            
            # Analyse des th√®mes s√©lectionn√©s
            with st.expander("üìä Th√®mes s√©lectionn√©s pour la g√©n√©ration"):
                selected_themes_analysis = results.get('selected_themes_by_keyword', {})
                
                for keyword, themes in selected_themes_analysis.items():
                    if themes:
                        st.markdown(f"**Th√®mes s√©lectionn√©s pour '{keyword}' :**")
                        themes_df = pd.DataFrame(themes)
                        if not themes_df.empty:
                            display_themes = themes_df[['nom', 'importance', 'intention', 'concepts']].copy()
                            display_themes.columns = ['Th√®me', 'Importance', 'Intention', 'Concepts']
                            st.dataframe(display_themes, use_container_width=True)
                            st.markdown("---")
            
            # Statistiques par th√®me et intention
            with st.expander("üìà R√©partition des questions g√©n√©r√©es"):
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("**R√©partition par th√®me:**")
                    theme_counts = df_results['Th√®me'].value_counts()
                    for theme, count in theme_counts.items():
                        st.markdown(f"- {theme}: {count} questions")
                
                with col2:
                    st.markdown("**R√©partition par intention:**")
                    intent_counts = df_results['Intention'].value_counts()
                    for intent, count in intent_counts.items():
                        st.markdown(f"- {intent}: {count} questions")
        
        # Statistiques d√©taill√©es
        with st.expander("üìä Statistiques d√©taill√©es"):
            st.markdown(f"**Questions g√©n√©r√©es:** {len(results['final_consolidated_data'])}")
            total_themes_selected = sum(len(themes) for themes in results.get('selected_themes_by_keyword', {}).values())
            st.markdown(f"**Th√®mes s√©lectionn√©s:** {total_themes_selected}")
            
            st.markdown("**R√©partition des suggestions par niveau:**")
            for level, count in results['level_counts'].items():
                st.markdown(f"- Niveau {level}: {count} suggestions")
            
            # R√©partition par mot-cl√©
            keyword_counts = suggestions_df['Mot-cl√©'].value_counts()
            st.markdown("**R√©partition par mot-cl√©:**")
            for keyword, count in keyword_counts.items():
                st.markdown(f"- {keyword}: {count} suggestions")
    
    # Affichage des r√©sultats interm√©diaires (suggestions seulement)
    elif (st.session_state.get('analysis_results') is not None and 
          st.session_state.analysis_results.get('stage') == 'themes_analyzed' and
          not st.session_state.analysis_metadata['generate_questions']):
        
        results = st.session_state.analysis_results
        metadata = st.session_state.analysis_metadata
        
        st.markdown("---")
        st.markdown("## üìä Suggestions collect√©es")
        
        # M√©triques sans questions
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Mots-cl√©s analys√©s", len(metadata['keywords']))
        with col2:
            st.metric("Suggestions collect√©es", len(results['all_suggestions']))
        with col3:
            max_level = 3 if metadata['enable_level3'] else (2 if metadata['enable_level2'] else 1)
            st.metric("Niveaux activ√©s", str(max_level))
        
        # Tableau des suggestions par niveau
        st.markdown("### üîç Suggestions collect√©es par niveau")
        
        # Cr√©er un DataFrame pour les suggestions
        suggestions_df = pd.DataFrame(results['all_suggestions'])
        suggestions_display = suggestions_df[['Mot-cl√©', 'Suggestion Google', 'Niveau', 'Parent']].copy()
        
        # Filtres par niveau
        available_levels = suggestions_df['Niveau'].unique().tolist()
        nivel_filter = st.multiselect(
            "Filtrer par niveau",
            options=available_levels,
            default=available_levels,
            format_func=lambda x: f"Niveau {x}"
        )
        
        if nivel_filter:
            filtered_suggestions = suggestions_display[suggestions_display['Niveau'].isin(nivel_filter)]
            st.dataframe(filtered_suggestions, use_container_width=True)

# TAB 2: Instructions d'utilisation
with tab2:
    st.markdown("""
    # üìñ Instructions d'utilisation
    
    ## üîç Processus d'analyse en 4 √©tapes
    
    ### 1. **Configuration**
    Entrez votre cl√© API OpenAI dans la barre lat√©rale
    
    ### 2. **Saisie des mots-cl√©s** 
    Entrez vos mots-cl√©s (un par ligne) dans la zone de texte
    
    ### 3. **Param√©trage**
    Ajustez le nombre de suggestions et questions finales selon vos besoins
    
    ### 4. **Analyse**
    Lancez l'analyse et obtenez vos questions conversationnelles optimis√©es
    
    ---
    
    ## ‚öôÔ∏è Fonctionnalit√©s principales
    
    - **Collecte automatique** des suggestions Google r√©elles
    - **G√©n√©ration intelligente** de questions par th√®me
    - **Consolidation avanc√©e** avec d√©duplication et scoring
    - **Export professionnel** en Excel et JSON
    
    ---
    
    ## üéØ Exemples de mots-cl√©s
    
    ```
    restaurant paris
    formation d√©veloppement web
    voyage √©cologique
    coaching personnel
    e-commerce bio
    h√¥tel spa luxe
    assurance auto jeune
    formation marketing digital
    ```
    
    ---
    
    ## üìä R√©sultats obtenus
    
    - ‚úÖ Questions conversationnelles optimis√©es SEO
    - ‚úÖ Tri√©es par pertinence d√©croissante
    - ‚úÖ Pr√™tes pour l'int√©gration dans votre contenu
    - ‚úÖ Format Excel professionnel avec colonnes organis√©es
    - ‚úÖ M√©tadonn√©es compl√®tes en JSON
    
    ---
    
    ## üöÄ Conseils d'optimisation
    
    ### Pour de meilleurs r√©sultats :
    
    - **Utilisez des mots-cl√©s sp√©cifiques** plut√¥t que g√©n√©riques
    - **Variez les intentions** (informationnelle, transactionnelle, navigationnelle)
    - **Adaptez la langue** selon votre audience cible
    - **Ajustez le nombre de suggestions** selon la profondeur d'analyse souhait√©e
    
    ### Param√®tres recommand√©s :
    
    - **D√©butant** : 5 suggestions, 10 questions finales
    - **Interm√©diaire** : 10 suggestions, 15 questions finales  
    - **Expert** : 15 suggestions, 25-50 questions finales
    
    ---
    
    ## üìà Applications SEO
    
    ### Utilisez vos questions pour :
    
    - **FAQ** : Int√©grer dans vos pages FAQ
    - **Blog** : Cr√©er des articles bas√©s sur les questions
    - **Featured Snippets** : Optimiser pour les extraits enrichis
    - **Recherche vocale** : Adapter votre contenu aux assistants vocaux
    - **Long tail** : Capturer le trafic des requ√™tes sp√©cifiques
    
    ---
    
    ## üîß Support technique
    
    En cas de probl√®me :
    1. V√©rifiez votre cl√© API OpenAI
    2. Assurez-vous d'avoir une connexion internet stable
    3. R√©duisez le nombre de mots-cl√©s si l'analyse est trop lente
    4. Contactez le support si les suggestions Google ne se chargent pas
    """)

# Footer
st.markdown("---")
st.markdown("*Outil d'optimisation SEO pour requ√™tes conversationnelles | Powered by GPT-4o mini & Streamlit*")