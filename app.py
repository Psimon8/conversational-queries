import streamlit as st
from openai import OpenAI
import pandas as pd
import json
import time
from collections import Counter
import re
import requests
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.express as px

# Configuration de la page Streamlit
st.set_page_config(
    page_title="SEO Conversational Queries Optimizer",
    page_icon="üîç",
    layout="wide"
)

# Titre principal
st.title("üîç Optimiseur de Requ√™tes Conversationnelles SEO")
st.subheader("Analyse th√©matique et suggestions Google pour l'optimisation SEO")

# Configuration de l'API OpenAI
st.sidebar.header("‚öôÔ∏è Configuration")
api_key = st.sidebar.text_input("Cl√© API OpenAI", type="password", help="Votre cl√© API OpenAI pour GPT-4o mini")

if api_key:
    client = OpenAI(api_key=api_key)
    st.sidebar.success("‚úÖ API configur√©e")
else:
    st.sidebar.warning("‚ö†Ô∏è Veuillez entrer votre cl√© API OpenAI")
    client = None

# Cr√©ation des onglets
tab1, tab2 = st.tabs(["üìä Analyse par Suggestions Google", "üéØ Analyse Th√©matique Classique"])

# Fonctions utilitaires communes
def call_gpt4o_mini(prompt, max_retries=3):
    """Appel √† l'API GPT-4o mini avec gestion d'erreurs"""
    if not client:
        st.error("‚ùå Cl√© API manquante")
        return None
    
    for attempt in range(max_retries):
        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": "Tu es un expert SEO sp√©cialis√© dans l'analyse des requ√™tes conversationnelles et l'optimisation pour les moteurs de recherche."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=1500,
                temperature=0.7
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)
                continue
            else:
                st.error(f"‚ùå Erreur API apr√®s {max_retries} tentatives: {str(e)}")
                return None

def get_google_suggestions(keyword, lang='fr', max_suggestions=10):
    """R√©cup√®re les suggestions Google pour un mot-cl√©"""
    url = "https://suggestqueries.google.com/complete/search"
    params = {
        "q": keyword,
        "gl": lang,
        "client": "chrome",
        "_": str(int(time.time() * 1000))
    }
    
    try:
        response = requests.get(url, params=params, timeout=5)
        response.raise_for_status()
        suggestions = response.json()[1][:max_suggestions]
        return suggestions
    except Exception as e:
        st.error(f"‚ùå Erreur lors de la r√©cup√©ration des suggestions pour '{keyword}': {str(e)}")
        return []

def extract_questions_from_response(response_text):
    """Extrait les questions d'une r√©ponse de GPT"""
    if not response_text:
        return []
    
    patterns = [
        r'^\d+\.?\s*["\']?([^"\']+\?)["\']?',  # Format num√©rot√© avec ?
        r'^-\s*["\']?([^"\']+\?)["\']?',       # Format avec tirets avec ?
        r'^‚Ä¢\s*["\']?([^"\']+\?)["\']?'        # Format avec puces avec ?
    ]
    
    questions = []
    lines = response_text.split('\n')
    
    for line in lines:
        line = line.strip()
        if not line or not line.endswith('?'):
            continue
            
        for pattern in patterns:
            match = re.match(pattern, line, re.MULTILINE)
            if match:
                question = match.group(1).strip()
                if len(question) > 10:
                    questions.append(question)
                break
        else:
            # Si aucun pattern ne correspond mais que la ligne se termine par ?
            if line.endswith('?') and len(line) > 10:
                questions.append(line)
    
    return questions

def create_mindmap_data(df):
    """Cr√©e les donn√©es pour la visualisation mindmap"""
    nodes = []
    edges = []
    
    # N≈ìud central
    nodes.append({"id": "root", "label": "Mots-cl√©s", "color": "#FF6B6B", "size": 30})
    
    # Couleurs pour les diff√©rents niveaux
    keyword_colors = ["#4ECDC4", "#45B7D1", "#96CEB4", "#FECA57", "#FF9FF3"]
    suggest_color = "#A8E6CF"
    question_color = "#FFD93D"
    
    # Grouper par mot-cl√©
    keyword_groups = df.groupby('Mot-cl√©')
    
    for i, (keyword, group) in enumerate(keyword_groups):
        keyword_color = keyword_colors[i % len(keyword_colors)]
        keyword_id = f"keyword_{i}"
        
        # N≈ìud mot-cl√©
        nodes.append({
            "id": keyword_id,
            "label": keyword,
            "color": keyword_color,
            "size": 25
        })
        edges.append({"source": "root", "target": keyword_id})
        
        # Grouper par suggestion
        suggest_groups = group.groupby('Suggestion Google')
        
        for j, (suggestion, suggest_group) in enumerate(suggest_groups):
            suggest_id = f"suggest_{i}_{j}"
            
            # N≈ìud suggestion
            nodes.append({
                "id": suggest_id,
                "label": suggestion[:30] + "..." if len(suggestion) > 30 else suggestion,
                "color": suggest_color,
                "size": 15
            })
            edges.append({"source": keyword_id, "target": suggest_id})
            
            # N≈ìuds questions
            for k, question in enumerate(suggest_group['Question Conversationnelle']):
                question_id = f"question_{i}_{j}_{k}"
                nodes.append({
                    "id": question_id,
                    "label": question[:40] + "..." if len(question) > 40 else question,
                    "color": question_color,
                    "size": 10
                })
                edges.append({"source": suggest_id, "target": question_id})
    
    return nodes, edges

# TAB 1: Analyse par Suggestions Google
with tab1:
    st.markdown("### üîç Analyse bas√©e sur les suggestions Google")
    
    # Input pour les mots-cl√©s
    keywords_input = st.text_area(
        "üéØ Entrez vos mots-cl√©s (un par ligne)",
        placeholder="restaurant paris\nh√¥tel luxe\nvoyage √©cologique",
        help="Entrez un ou plusieurs mots-cl√©s, un par ligne"
    )
    
    # Configuration
    col1, col2 = st.columns(2)
    with col1:
        max_suggestions = st.slider("Nombre de suggestions par mot-cl√©", 5, 15, 10)
    with col2:
        lang = st.selectbox("Langue", ["fr", "en", "es", "de", "it"], index=0)
    
    if keywords_input and api_key:
        keywords = [kw.strip() for kw in keywords_input.split('\n') if kw.strip()]
        
        if st.button("üöÄ Analyser les suggestions", type="primary"):
            if not keywords:
                st.error("‚ùå Veuillez entrer au moins un mot-cl√©")
            else:
                # Progress tracking
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # Container pour les r√©sultats
                results_container = st.container()
                
                # √âtape 1: Collecte des suggestions
                status_text.text("‚è≥ √âtape 1/4: Collecte des suggestions Google...")
                all_data = []
                
                for i, keyword in enumerate(keywords):
                    suggestions = get_google_suggestions(keyword, lang, max_suggestions)
                    
                    for suggestion in suggestions:
                        all_data.append({
                            'Mot-cl√©': keyword,
                            'Suggestion Google': suggestion
                        })
                    
                    progress_bar.progress((i + 1) * 20 // len(keywords))
                    time.sleep(0.5)  # √âviter le rate limiting
                
                if not all_data:
                    st.error("‚ùå Aucune suggestion trouv√©e")
                else:
                    # √âtape 2: G√©n√©ration des questions conversationnelles
                    status_text.text("‚è≥ √âtape 2/4: G√©n√©ration des questions conversationnelles...")
                    
                    questions_data = []
                    processed = 0
                    total_items = len(all_data)
                    
                    for item in all_data:
                        keyword = item['Mot-cl√©']
                        suggestion = item['Suggestion Google']
                        
                        prompt = f"""
                        Bas√© sur le mot-cl√© "{keyword}" et la suggestion Google "{suggestion}", 
                        g√©n√®re 3 √† 5 questions conversationnelles SEO pertinentes au format question.
                        
                        Les questions doivent :
                        - √ätre naturelles et conversationnelles
                        - Optimis√©es pour la recherche vocale
                        - Pertinentes pour l'intention de recherche
                        - Se terminer par un point d'interrogation
                        
                        Pr√©sente-les sous forme de liste num√©rot√©e.
                        """
                        
                        response = call_gpt4o_mini(prompt)
                        if response:
                            questions = extract_questions_from_response(response)
                            for question in questions:
                                questions_data.append({
                                    'Mot-cl√©': keyword,
                                    'Suggestion Google': suggestion,
                                    'Question Conversationnelle': question
                                })
                        
                        processed += 1
                        progress_bar.progress(20 + (processed * 50 // total_items))
                        time.sleep(0.8)  # √âviter le rate limiting
                    
                    if not questions_data:
                        st.error("‚ùå Aucune question g√©n√©r√©e")
                    else:
                        # √âtape 3: R√©analyse et s√©lection finale
                        status_text.text("‚è≥ √âtape 3/4: R√©analyse et s√©lection finale...")
                        
                        all_questions = [item['Question Conversationnelle'] for item in questions_data]
                        questions_text = "\n".join([f"- {q}" for q in all_questions])
                        
                        # S√©lecteur pour le nombre de questions finales
                        num_final_questions = st.slider(
                            "Nombre de questions finales √† s√©lectionner",
                            min_value=5,
                            max_value=min(20, len(all_questions)),
                            value=min(10, len(all_questions)),
                            key="final_questions_selector"
                        )
                        
                        final_selection_prompt = f"""
                        Analyse cette liste de questions conversationnelles et s√©lectionne les {num_final_questions} meilleures questions selon ces crit√®res :
                        
                        1. Pertinence SEO et potentiel de recherche
                        2. Qualit√© conversationnelle et naturelle
                        3. Diversit√© des intentions de recherche
                        4. Optimisation pour la recherche vocale
                        
                        Questions √† analyser :
                        {questions_text}
                        
                        Retourne uniquement les {num_final_questions} meilleures questions, une par ligne, sans num√©rotation.
                        """
                        
                        final_response = call_gpt4o_mini(final_selection_prompt)
                        final_questions = []
                        
                        if final_response:
                            final_questions = [q.strip() for q in final_response.split('\n') if q.strip() and q.strip().endswith('?')]
                        
                        progress_bar.progress(90)
                        
                        # √âtape 4: Pr√©paration des r√©sultats finaux
                        status_text.text("‚è≥ √âtape 4/4: Pr√©paration des r√©sultats...")
                        
                        # Filtrer les donn√©es pour ne garder que les questions s√©lectionn√©es
                        final_data = [
                            item for item in questions_data 
                            if item['Question Conversationnelle'] in final_questions
                        ]
                        
                        if not final_data:
                            # Si aucune correspondance exacte, prendre les premi√®res
                            final_data = questions_data[:num_final_questions]
                        
                        progress_bar.progress(100)
                        status_text.text("‚úÖ Analyse termin√©e !")
                        
                        # Affichage des r√©sultats
                        with results_container:
                            st.markdown("## üìä R√©sultats de l'analyse")
                            
                            # M√©triques
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("Mots-cl√©s analys√©s", len(keywords))
                            with col2:
                                st.metric("Suggestions collect√©es", len(all_data))
                            with col3:
                                st.metric("Questions g√©n√©r√©es", len(questions_data))
                            with col4:
                                st.metric("Questions finales", len(final_data))
                            
                            # Tableau des r√©sultats
                            st.markdown("### üìã Tableau des r√©sultats")
                            df_results = pd.DataFrame(final_data)
                            st.dataframe(df_results, use_container_width=True)
                            
                            # Visualisation Mindmap
                            st.markdown("### üó∫Ô∏è Carte mentale des r√©sultats")
                            
                            if len(final_data) > 0:
                                try:
                                    # Graphique en r√©seau avec Plotly
                                    fig = go.Figure()
                                    
                                    # Pr√©parer les donn√©es pour le graphique en r√©seau
                                    keywords_unique = df_results['Mot-cl√©'].unique()
                                    
                                    # Graphique en sunburst comme alternative
                                    labels = []
                                    parents = []
                                    values = []
                                    
                                    # Niveau racine
                                    labels.append("Mots-cl√©s")
                                    parents.append("")
                                    values.append(len(final_data))
                                    
                                    # Niveau mots-cl√©s
                                    for keyword in keywords_unique:
                                        labels.append(keyword)
                                        parents.append("Mots-cl√©s")
                                        keyword_data = df_results[df_results['Mot-cl√©'] == keyword]
                                        values.append(len(keyword_data))
                                        
                                        # Niveau suggestions
                                        suggestions_unique = keyword_data['Suggestion Google'].unique()
                                        for suggestion in suggestions_unique:
                                            suggest_label = suggestion[:30] + "..." if len(suggestion) > 30 else suggestion
                                            labels.append(suggest_label)
                                            parents.append(keyword)
                                            suggest_data = keyword_data[keyword_data['Suggestion Google'] == suggestion]
                                            values.append(len(suggest_data))
                                    
                                    fig = go.Figure(go.Sunburst(
                                        labels=labels,
                                        parents=parents,
                                        values=values,
                                        branchvalues="total",
                                    ))
                                    
                                    fig.update_layout(
                                        title="R√©partition hi√©rarchique des r√©sultats",
                                        height=600
                                    )
                                    
                                    st.plotly_chart(fig, use_container_width=True)
                                    
                                except Exception as e:
                                    st.warning(f"‚ö†Ô∏è Impossible d'afficher la visualisation: {str(e)}")
                            
                            # Export des r√©sultats
                            st.markdown("### üì§ Export des r√©sultats")
                            
                            col1, col2 = st.columns(2)
                            with col1:
                                csv = df_results.to_csv(index=False, encoding='utf-8')
                                st.download_button(
                                    label="üìä T√©l√©charger CSV",
                                    data=csv,
                                    file_name="questions_conversationnelles_suggestions.csv",
                                    mime="text/csv"
                                )
                            
                            with col2:
                                json_data = df_results.to_json(orient='records', force_ascii=False, indent=2)
                                st.download_button(
                                    label="üìã T√©l√©charger JSON",
                                    data=json_data,
                                    file_name="questions_conversationnelles_suggestions.json",
                                    mime="application/json"
                                )

# TAB 2: Analyse Th√©matique Classique (code existant)
with tab2:
    st.markdown("### üéØ Analyse th√©matique classique")
    
    # Input pour la th√©matique
    thematique = st.text_input(
        "üéØ Th√©matique √† analyser",
        placeholder="Ex: r√©servation restaurant, voyage √©cologique, formation en ligne...",
        help="Entrez la th√©matique pour laquelle vous souhaitez identifier les requ√™tes conversationnelles"
    )

    # Fonctions utilitaires
    def extract_queries_from_response(response_text):
        """Extrait les requ√™tes d'une r√©ponse de GPT"""
        if not response_text:
            return []
        
        # Patterns pour extraire les requ√™tes
        patterns = [
            r'^\d+\.?\s*["\']?([^"\']+)["\']?',  # Format num√©rot√©
            r'^-\s*["\']?([^"\']+)["\']?',       # Format avec tirets
            r'^‚Ä¢\s*["\']?([^"\']+)["\']?'        # Format avec puces
        ]
        
        queries = []
        lines = response_text.split('\n')
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            for pattern in patterns:
                match = re.match(pattern, line, re.MULTILINE)
                if match:
                    query = match.group(1).strip()
                    if len(query) > 10:  # Filtrer les r√©ponses trop courtes
                        queries.append(query)
                    break
        
        return queries[:10]  # Limiter √† 10 requ√™tes

    def deduplicate_queries(queries):
        """D√©doublonne les requ√™tes en tenant compte des similarit√©s"""
        if not queries:
            return []
        
        # Normalisation pour comparaison
        normalized = {}
        for query in queries:
            # Suppression ponctuation et mise en minuscules
            normalized_query = re.sub(r'[^\w\s]', '', query.lower()).strip()
            if normalized_query not in normalized:
                normalized[normalized_query] = query
        
        return list(normalized.values())

    # Interface principale pour l'analyse th√©matique
    if thematique and api_key:
        
        # Bouton pour lancer l'analyse
        if st.button("üöÄ Lancer l'analyse th√©matique compl√®te", type="primary"):
            
            # Progress bar
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # Container pour les r√©sultats
            results_container = st.container()
            
            with results_container:
                st.markdown("## üìä R√©sultats de l'analyse th√©matique")
                
                # √âtape 1: Collecte initiale
                status_text.text("‚è≥ √âtape 1/3: Collecte initiale des requ√™tes...")
                progress_bar.progress(10)
                
                prompt_etape1 = f"En te basant sur la th√©matique '{thematique}', donne-moi les 10 meilleures requ√™tes conversationnelles recherch√©es par les utilisateurs. Pr√©sente-les sous forme de liste num√©rot√©e."
                
                # Simulation de 4 appels LLM (ici on utilise GPT-4o mini avec des variations)
                llm_responses = []
                
                for i in range(4):
                    variation_prompt = f"{prompt_etape1}\n\nVariation {i+1}: Focus sur les intentions de recherche sp√©cifiques √† cette th√©matique."
                    response = call_gpt4o_mini(variation_prompt)
                    if response:
                        queries = extract_queries_from_response(response)
                        llm_responses.extend(queries)
                    progress_bar.progress(10 + (i+1) * 15)
                    time.sleep(1)  # √âviter le rate limiting
                
                # Affichage des r√©sultats √âtape 1
                st.markdown("### üìã √âtape 1 - Requ√™tes collect√©es")
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Requ√™tes collect√©es", len(llm_responses))
                with col2:
                    st.metric("Requ√™tes uniques", len(set(llm_responses)))
                
                # D√©doublonnage pour √©tape 2
                status_text.text("‚è≥ √âtape 2/3: Affinage et s√©lection...")
                progress_bar.progress(70)
                
                deduplicated_queries = deduplicate_queries(llm_responses)
                queries_list = "\n".join([f"- {query}" for query in deduplicated_queries])
                
                prompt_etape2 = f"""En te basant sur la th√©matique '{thematique}' et sur cette liste de requ√™tes conversationnelles, fais-moi une s√©lection d'un top 10 des meilleures requ√™tes conversationnelles :

{queries_list}

Crit√®res de s√©lection :
- Pertinence pour la th√©matique
- Potentiel de volume de recherche
- Intention de recherche claire
- Adaptabilit√© au SEO conversationnel"""

                refined_response = call_gpt4o_mini(prompt_etape2)
                refined_queries = extract_queries_from_response(refined_response) if refined_response else []
                
                progress_bar.progress(85)
                
                # √âtape 3: Finalisation
                status_text.text("‚è≥ √âtape 3/3: Finalisation par intention de recherche...")
                
                if refined_queries:
                    final_queries_list = "\n".join([f"- {query}" for query in refined_queries])
                    prompt_etape3 = f"""En te basant sur l'intention de recherche, d√©doublonne cette liste et fournis-moi le top 10 des meilleures requ√™tes conversationnelles pour la th√©matique '{thematique}':

{final_queries_list}

Analyse chaque requ√™te selon :
1. L'intention de recherche (informationnelle, navigationnelle, transactionnelle)
2. Le potentiel SEO
3. La pertinence pour les assistants vocaux
4. L'adaptabilit√© au contenu conversationnel

Pr√©sente le r√©sultat final sous forme de liste num√©rot√©e."""
                    
                    final_response = call_gpt4o_mini(prompt_etape3)
                    final_queries = extract_queries_from_response(final_response) if final_response else refined_queries
                else:
                    final_queries = []
                
                progress_bar.progress(100)
                status_text.text("‚úÖ Analyse termin√©e !")
                
                # Affichage des r√©sultats finaux
                st.markdown("### üèÜ R√©sultats finaux - Top 10 des requ√™tes conversationnelles")
                
                if final_queries:
                    # M√©triques
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Requ√™tes finales", len(final_queries))
                    with col2:
                        st.metric("Taux de conversion", f"{(len(final_queries)/max(len(llm_responses), 1)*100):.1f}%")
                    with col3:
                        st.metric("√âtapes compl√©t√©es", "3/3")
                    
                    # Liste des requ√™tes finales
                    st.markdown("#### üìù Requ√™tes s√©lectionn√©es:")
                    for i, query in enumerate(final_queries, 1):
                        st.markdown(f"**{i}.** {query}")
                    
                    # Export des donn√©es
                    st.markdown("### üì§ Export des r√©sultats")
                    
                    # Cr√©ation du DataFrame pour export
                    export_data = {
                        'Rang': range(1, len(final_queries) + 1),
                        'Requ√™te conversationnelle': final_queries,
                        'Th√©matique': [thematique] * len(final_queries)
                    }
                    df = pd.DataFrame(export_data)
                    
                    # Boutons d'export
                    col1, col2 = st.columns(2)
                    with col1:
                        csv = df.to_csv(index=False, encoding='utf-8')
                        st.download_button(
                            label="üìä T√©l√©charger CSV",
                            data=csv,
                            file_name=f"requetes_conversationnelles_{thematique.replace(' ', '_')}.csv",
                            mime="text/csv"
                        )
                    
                    with col2:
                        json_data = df.to_json(orient='records', force_ascii=False, indent=2)
                        st.download_button(
                            label="üìã T√©l√©charger JSON",
                            data=json_data,
                            file_name=f"requetes_conversationnelles_{thematique.replace(' ', '_')}.json",
                            mime="application/json"
                        )
                    
                    # Analyse d√©taill√©e
                    with st.expander("üìä Analyse d√©taill√©e du processus"):
                        st.markdown(f"**Th√©matique analys√©e:** {thematique}")
                        st.markdown(f"**Requ√™tes collect√©es initialement:** {len(llm_responses)}")
                        st.markdown(f"**Requ√™tes apr√®s d√©doublonnage:** {len(deduplicated_queries)}")
                        st.markdown(f"**Requ√™tes finales s√©lectionn√©es:** {len(final_queries)}")
                        st.markdown(f"**Efficacit√© du processus:** {(len(final_queries)/max(len(llm_responses), 1)*100):.1f}%")
                
                else:
                    st.error("‚ùå Aucune requ√™te n'a pu √™tre extraite. V√©rifiez votre th√©matique et r√©essayez.")

    else:
        # Instructions d'utilisation pour l'analyse th√©matique
        st.markdown("""
        ## üìñ Instructions d'utilisation - Analyse Th√©matique
        
        1. **Configurez votre cl√© API OpenAI** dans la barre lat√©rale
        2. **Entrez la th√©matique** √† analyser dans le champ ci-dessus
        3. **Cliquez sur "Lancer l'analyse th√©matique compl√®te"** pour d√©marrer le processus
        
        ### üéØ Exemples de th√©matiques:
        - "R√©servation restaurant en ligne"
        - "Formation d√©veloppement web"
        - "Voyage √©cologique et durable"
        - "E-commerce produits bio"
        - "Coaching personnel √† distance"
        
        ### ‚ö° Le processus automatis√© comprend:
        - **√âtape 1:** Collecte initiale via GPT-4o mini avec variations
        - **√âtape 2:** Affinage et s√©lection des meilleures requ√™tes
        - **√âtape 3:** Finalisation bas√©e sur l'intention de recherche
        - **Export:** T√©l√©chargement des r√©sultats en CSV/JSON
        """)

# Instructions globales
if not api_key:
    st.markdown("""
    ## üìñ Instructions g√©n√©rales
    
    ### üîç Deux m√©thodes d'analyse disponibles:
    
    **1. Analyse par Suggestions Google** (Onglet 1)
    - Saisissez vos mots-cl√©s
    - R√©cup√©ration automatique des suggestions Google
    - G√©n√©ration de questions conversationnelles par GPT
    - Visualisation en tableau et carte mentale
    
    **2. Analyse Th√©matique Classique** (Onglet 2)
    - Saisissez une th√©matique g√©n√©rale
    - M√©thode en 3 √©tapes avec variations GPT
    - Focus sur l'intention de recherche
    
    ### ‚öôÔ∏è Configuration requise:
    - Cl√© API OpenAI (configur√©e dans la barre lat√©rale)
    - Connexion internet pour les suggestions Google
    """)

# Footer
st.markdown("---")
st.markdown("*Outil d'optimisation SEO pour requ√™tes conversationnelles | Powered by GPT-4o mini & Streamlit*")
