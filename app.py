import streamlit as st
from openai import OpenAI
import pandas as pd
import json
import time
from collections import Counter
import re
import requests
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.express as px
from io import BytesIO

# Configuration de la page Streamlit
st.set_page_config(
    page_title="SEO Conversational Queries Optimizer",
    page_icon="üîç",
    layout="wide"
)

# Titre principal
st.title("üîç Optimiseur de Requ√™tes Conversationnelles SEO")
st.subheader("Analyse th√©matique et suggestions Google pour l'optimisation SEO")

# Configuration de l'API OpenAI
st.sidebar.header("‚öôÔ∏è Configuration")
api_key = st.sidebar.text_input("Cl√© API OpenAI", type="password", help="Votre cl√© API OpenAI pour GPT-4o mini")

if api_key:
    client = OpenAI(api_key=api_key)
    st.sidebar.success("‚úÖ API configur√©e")
else:
    st.sidebar.warning("‚ö†Ô∏è Veuillez entrer votre cl√© API OpenAI")
    client = None

# Cr√©ation des onglets
tab1, tab2 = st.tabs(["üìä Analyse par Suggestions Google", "üéØ Analyse Th√©matique Classique"])

# Fonctions utilitaires communes
def call_gpt4o_mini(prompt, max_retries=3):
    """Appel √† l'API GPT-4o mini avec gestion d'erreurs"""
    if not client:
        st.error("‚ùå Cl√© API manquante")
        return None
    
    for attempt in range(max_retries):
        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": "Tu es un expert SEO sp√©cialis√© dans l'analyse des requ√™tes conversationnelles et l'optimisation pour les moteurs de recherche."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=1500,
                temperature=0.7
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)
                continue
            else:
                st.error(f"‚ùå Erreur API apr√®s {max_retries} tentatives: {str(e)}")
                return None

def get_google_suggestions(keyword, lang='fr', max_suggestions=10):
    """R√©cup√®re les suggestions Google pour un mot-cl√©"""
    url = "https://suggestqueries.google.com/complete/search"
    params = {
        "q": keyword,
        "gl": lang,
        "client": "chrome",
        "_": str(int(time.time() * 1000))
    }
    
    try:
        response = requests.get(url, params=params, timeout=5)
        response.raise_for_status()
        suggestions = response.json()[1][:max_suggestions]
        return suggestions
    except Exception as e:
        st.error(f"‚ùå Erreur lors de la r√©cup√©ration des suggestions pour '{keyword}': {str(e)}")
        return []

def extract_questions_from_response(response_text):
    """Extrait les questions d'une r√©ponse de GPT"""
    if not response_text:
        return []
    
    patterns = [
        r'^\d+\.?\s*["\']?([^"\']+\?)["\']?',  # Format num√©rot√© avec ?
        r'^-\s*["\']?([^"\']+\?)["\']?',       # Format avec tirets avec ?
        r'^‚Ä¢\s*["\']?([^"\']+\?)["\']?'        # Format avec puces avec ?
    ]
    
    questions = []
    lines = response_text.split('\n')
    
    for line in lines:
        line = line.strip()
        if not line or not line.endswith('?'):
            continue
            
        for pattern in patterns:
            match = re.match(pattern, line, re.MULTILINE)
            if match:
                question = match.group(1).strip()
                if len(question) > 10:
                    questions.append(question)
                break
        else:
            # Si aucun pattern ne correspond mais que la ligne se termine par ?
            if line.endswith('?') and len(line) > 10:
                questions.append(line)
    
    return questions

def consolidate_and_deduplicate(questions_data, target_count):
    """Consolide et d√©duplique les questions en gardant les plus pertinentes"""
    if not questions_data:
        return []
    
    # Cr√©er un dictionnaire pour comptabiliser les occurrences et garder les m√©tadonn√©es
    question_stats = {}
    
    for item in questions_data:
        question = item['Question Conversationnelle'].strip()
        # Normalisation pour d√©tecter les similitudes
        normalized = re.sub(r'[^\w\s]', '', question.lower()).strip()
        
        if normalized not in question_stats:
            question_stats[normalized] = {
                'original_question': question,
                'count': 1,
                'suggestions': [item['Suggestion Google']],
                'keywords': [item['Mot-cl√©']],
                'first_occurrence': item
            }
        else:
            question_stats[normalized]['count'] += 1
            if item['Suggestion Google'] not in question_stats[normalized]['suggestions']:
                question_stats[normalized]['suggestions'].append(item['Suggestion Google'])
            if item['Mot-cl√©'] not in question_stats[normalized]['keywords']:
                question_stats[normalized]['keywords'].append(item['Mot-cl√©'])
    
    # Trier par nombre d'occurrences (pertinence) et prendre les meilleures
    sorted_questions = sorted(
        question_stats.values(),
        key=lambda x: (x['count'], len(x['keywords'])),
        reverse=True
    )
    
    # Prendre le nombre demand√© de questions
    final_questions = []
    for i, q_data in enumerate(sorted_questions[:target_count]):
        final_questions.append({
            'Requ√™tes Conversationnelles': q_data['original_question'],
            'Suggestion': q_data['suggestions'][0],  # Premi√®re suggestion associ√©e
            'Mot-cl√©': q_data['keywords'][0],  # Premier mot-cl√© associ√©
            'Score_Pertinence': q_data['count'],
            'Nb_Keywords': len(q_data['keywords']),
            'Nb_Suggestions': len(q_data['suggestions'])
        })
    
    return final_questions

def create_excel_file(df):
    """Cr√©e un fichier Excel avec formatage"""
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='Questions_Conversationnelles')
        
        # Acc√©der au workbook et worksheet pour le formatage
        workbook = writer.book
        worksheet = writer.sheets['Questions_Conversationnelles']
        
        # Ajuster la largeur des colonnes
        worksheet.column_dimensions['A'].width = 60  # Questions
        worksheet.column_dimensions['B'].width = 40  # Suggestions
        worksheet.column_dimensions['C'].width = 25  # Mots-cl√©s
        
        # Formatage de l'en-t√™te
        from openpyxl.styles import Font, PatternFill
        header_font = Font(bold=True)
        header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
        
        for cell in worksheet[1]:
            cell.font = header_font
            cell.fill = header_fill
    
    output.seek(0)
    return output

# TAB 1: Analyse par Suggestions Google
with tab1:
    st.markdown("### üîç Analyse bas√©e sur les suggestions Google")
    
    # Input pour les mots-cl√©s
    keywords_input = st.text_area(
        "üéØ Entrez vos mots-cl√©s (un par ligne)",
        placeholder="restaurant paris\nh√¥tel luxe\nvoyage √©cologique",
        help="Entrez un ou plusieurs mots-cl√©s, un par ligne"
    )
    
    # Configuration am√©lior√©e
    col1, col2, col3 = st.columns(3)
    with col1:
        max_suggestions = st.slider(
            "Nombre de suggestions par mot-cl√©", 
            min_value=3, 
            max_value=15, 
            value=10,
            help="Nombre de suggestions Google √† r√©cup√©rer pour chaque mot-cl√©"
        )
    with col2:
        final_questions_count = st.slider(
            "Nombre de questions finales",
            min_value=5,
            max_value=50,
            value=15,
            help="Nombre de questions conversationnelles √† conserver apr√®s consolidation"
        )
    with col3:
        lang = st.selectbox("Langue", ["fr", "en", "es", "de", "it"], index=0)
    
    if keywords_input and api_key:
        keywords = [kw.strip() for kw in keywords_input.split('\n') if kw.strip()]
        
        if st.button("üöÄ Analyser les suggestions", type="primary"):
            if not keywords:
                st.error("‚ùå Veuillez entrer au moins un mot-cl√©")
            else:
                # Progress tracking
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # Container pour les r√©sultats
                results_container = st.container()
                
                # √âtape 1: Collecte des suggestions
                status_text.text("‚è≥ √âtape 1/4: Collecte des suggestions Google...")
                all_suggestions = []
                
                for i, keyword in enumerate(keywords):
                    suggestions = get_google_suggestions(keyword, lang, max_suggestions)
                    
                    for suggestion in suggestions:
                        all_suggestions.append({
                            'Mot-cl√©': keyword,
                            'Suggestion Google': suggestion
                        })
                    
                    progress_bar.progress((i + 1) * 20 // len(keywords))
                    time.sleep(0.5)  # √âviter le rate limiting
                
                if not all_suggestions:
                    st.error("‚ùå Aucune suggestion trouv√©e")
                else:
                    st.info(f"‚úÖ {len(all_suggestions)} suggestions collect√©es pour {len(keywords)} mot(s)-cl√©(s)")
                    
                    # √âtape 2: G√©n√©ration des questions conversationnelles (10 par suggestion)
                    status_text.text("‚è≥ √âtape 2/4: G√©n√©ration de 10 questions par suggestion...")
                    
                    all_questions_data = []
                    processed = 0
                    total_items = len(all_suggestions)
                    
                    for item in all_suggestions:
                        keyword = item['Mot-cl√©']
                        suggestion = item['Suggestion Google']
                        
                        prompt = f"""
                        Bas√© sur le mot-cl√© "{keyword}" et la suggestion Google "{suggestion}", 
                        g√©n√®re EXACTEMENT 10 questions conversationnelles SEO pertinentes au format question.
                        
                        Les questions doivent :
                        - √ätre naturelles et conversationnelles
                        - Optimis√©es pour la recherche vocale
                        - Pertinentes pour l'intention de recherche
                        - Se terminer par un point d'interrogation
                        - √ätre vari√©es dans leur formulation
                        
                        Pr√©sente-les sous forme de liste num√©rot√©e de 1 √† 10.
                        """
                        
                        response = call_gpt4o_mini(prompt)
                        if response:
                            questions = extract_questions_from_response(response)
                            # S'assurer d'avoir exactement 10 questions
                            for question in questions[:10]:
                                all_questions_data.append({
                                    'Mot-cl√©': keyword,
                                    'Suggestion Google': suggestion,
                                    'Question Conversationnelle': question
                                })
                        
                        processed += 1
                        progress_bar.progress(20 + (processed * 50 // total_items))
                        time.sleep(0.8)  # √âviter le rate limiting
                        
                        # Affichage du progr√®s en temps r√©el
                        current_questions = len(all_questions_data)
                        status_text.text(f"‚è≥ √âtape 2/4: {current_questions} questions g√©n√©r√©es...")
                    
                    if not all_questions_data:
                        st.error("‚ùå Aucune question g√©n√©r√©e")
                    else:
                        st.info(f"‚úÖ {len(all_questions_data)} questions g√©n√©r√©es au total")
                        
                        # √âtape 3: Consolidation et d√©duplication
                        status_text.text("‚è≥ √âtape 3/4: Consolidation et d√©duplication...")
                        progress_bar.progress(80)
                        
                        # Utiliser la fonction de consolidation am√©lior√©e
                        final_consolidated_data = consolidate_and_deduplicate(
                            all_questions_data, 
                            final_questions_count
                        )
                        
                        progress_bar.progress(90)
                        
                        # √âtape 4: Pr√©paration des r√©sultats finaux
                        status_text.text("‚è≥ √âtape 4/4: Pr√©paration des r√©sultats...")
                        
                        progress_bar.progress(100)
                        status_text.text("‚úÖ Analyse termin√©e !")
                        
                        # Affichage des r√©sultats
                        with results_container:
                            st.markdown("## üìä R√©sultats de l'analyse")
                            
                            # M√©triques am√©lior√©es
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("Mots-cl√©s analys√©s", len(keywords))
                            with col2:
                                st.metric("Suggestions collect√©es", len(all_suggestions))
                            with col3:
                                st.metric("Questions g√©n√©r√©es", len(all_questions_data))
                            with col4:
                                st.metric("Questions finales", len(final_consolidated_data))
                            
                            # Tableau des r√©sultats avec tri par pertinence
                            st.markdown("### üìã Tableau des r√©sultats (par pertinence d√©croissante)")
                            
                            # Cr√©er le DataFrame avec les colonnes dans l'ordre demand√©
                            df_results = pd.DataFrame(final_consolidated_data)
                            
                            # R√©organiser les colonnes selon vos sp√©cifications
                            df_display = df_results[['Requ√™tes Conversationnelles', 'Suggestion', 'Mot-cl√©']].copy()
                            
                            st.dataframe(df_display, use_container_width=True)
                            
                            # Statistiques de consolidation
                            with st.expander("üìä Statistiques de consolidation"):
                                st.markdown(f"**Taux de consolidation:** {(len(all_questions_data) - len(final_consolidated_data)) / len(all_questions_data) * 100:.1f}%")
                                st.markdown(f"**Questions √©limin√©es:** {len(all_questions_data) - len(final_consolidated_data)}")
                                st.markdown(f"**Questions conserv√©es:** {len(final_consolidated_data)}")
                                
                                # Top mots-cl√©s
                                keyword_counts = df_results['Mot-cl√©'].value_counts()
                                st.markdown("**R√©partition par mot-cl√©:**")
                                for keyword, count in keyword_counts.items():
                                    st.markdown(f"- {keyword}: {count} questions")
                            
                            # Visualisation am√©lior√©e
                            st.markdown("### üó∫Ô∏è R√©partition des r√©sultats")
                            
                            if len(final_consolidated_data) > 0:
                                try:
                                    # Graphique en barres de la r√©partition par mot-cl√©
                                    keyword_counts = df_results['Mot-cl√©'].value_counts()
                                    
                                    fig_bar = px.bar(
                                        x=keyword_counts.index,
                                        y=keyword_counts.values,
                                        title="R√©partition des questions par mot-cl√©",
                                        labels={'x': 'Mots-cl√©s', 'y': 'Nombre de questions'}
                                    )
                                    st.plotly_chart(fig_bar, use_container_width=True)
                                    
                                    # Graphique en secteurs
                                    fig_pie = px.pie(
                                        values=keyword_counts.values,
                                        names=keyword_counts.index,
                                        title="Proportion des questions par mot-cl√©"
                                    )
                                    st.plotly_chart(fig_pie, use_container_width=True)
                                    
                                except Exception as e:
                                    st.warning(f"‚ö†Ô∏è Impossible d'afficher la visualisation: {str(e)}")
                            
                            # Export am√©lior√© des r√©sultats
                            st.markdown("### üì§ Export des r√©sultats")
                            
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                # Export Excel
                                excel_file = create_excel_file(df_display)
                                st.download_button(
                                    label="üìä T√©l√©charger Excel",
                                    data=excel_file,
                                    file_name="questions_conversationnelles_consolidees.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                )
                            
                            with col2:
                                # Export JSON avec m√©tadonn√©es
                                export_json = {
                                    "metadata": {
                                        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                                        "keywords_analyzed": keywords,
                                        "total_questions_generated": len(all_questions_data),
                                        "final_questions_count": len(final_consolidated_data),
                                        "consolidation_rate": f"{(len(all_questions_data) - len(final_consolidated_data)) / len(all_questions_data) * 100:.1f}%"
                                    },
                                    "results": final_consolidated_data
                                }
                                
                                json_data = json.dumps(export_json, ensure_ascii=False, indent=2)
                                st.download_button(
                                    label="üìã T√©l√©charger JSON",
                                    data=json_data,
                                    file_name="questions_conversationnelles_consolidees.json",
                                    mime="application/json"
                                )

# TAB 2: Analyse Th√©matique Classique (code existant)
with tab2:
    st.markdown("### üéØ Analyse th√©matique classique")
    
    # Input pour la th√©matique
    thematique = st.text_input(
        "üéØ Th√©matique √† analyser",
        placeholder="Ex: r√©servation restaurant, voyage √©cologique, formation en ligne...",
        help="Entrez la th√©matique pour laquelle vous souhaitez identifier les requ√™tes conversationnelles"
    )

    # Fonctions utilitaires
    def extract_queries_from_response(response_text):
        """Extrait les requ√™tes d'une r√©ponse de GPT"""
        if not response_text:
            return []
        
        # Patterns pour extraire les requ√™tes
        patterns = [
            r'^\d+\.?\s*["\']?([^"\']+)["\']?',  # Format num√©rot√©
            r'^-\s*["\']?([^"\']+)["\']?',       # Format avec tirets
            r'^‚Ä¢\s*["\']?([^"\']+)["\']?'        # Format avec puces
        ]
        
        queries = []
        lines = response_text.split('\n')
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            for pattern in patterns:
                match = re.match(pattern, line, re.MULTILINE)
                if match:
                    query = match.group(1).strip()
                    if len(query) > 10:  # Filtrer les r√©ponses trop courtes
                        queries.append(query)
                    break
        
        return queries[:10]  # Limiter √† 10 requ√™tes

    def deduplicate_queries(queries):
        """D√©doublonne les requ√™tes en tenant compte des similarit√©s"""
        if not queries:
            return []
        
        # Normalisation pour comparaison
        normalized = {}
        for query in queries:
            # Suppression ponctuation et mise en minuscules
            normalized_query = re.sub(r'[^\w\s]', '', query.lower()).strip()
            if normalized_query not in normalized:
                normalized[normalized_query] = query
        
        return list(normalized.values())

    # Interface principale pour l'analyse th√©matique
    if thematique and api_key:
        
        # Bouton pour lancer l'analyse
        if st.button("üöÄ Lancer l'analyse th√©matique compl√®te", type="primary"):
            
            # Progress bar
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # Container pour les r√©sultats
            results_container = st.container()
            
            with results_container:
                st.markdown("## üìä R√©sultats de l'analyse th√©matique")
                
                # √âtape 1: Collecte initiale
                status_text.text("‚è≥ √âtape 1/3: Collecte initiale des requ√™tes...")
                progress_bar.progress(10)
                
                prompt_etape1 = f"En te basant sur la th√©matique '{thematique}', donne-moi les 10 meilleures requ√™tes conversationnelles recherch√©es par les utilisateurs. Pr√©sente-les sous forme de liste num√©rot√©e."
                
                # Simulation de 4 appels LLM (ici on utilise GPT-4o mini avec des variations)
                llm_responses = []
                
                for i in range(4):
                    variation_prompt = f"{prompt_etape1}\n\nVariation {i+1}: Focus sur les intentions de recherche sp√©cifiques √† cette th√©matique."
                    response = call_gpt4o_mini(variation_prompt)
                    if response:
                        queries = extract_queries_from_response(response)
                        llm_responses.extend(queries)
                    progress_bar.progress(10 + (i+1) * 15)
                    time.sleep(1)  # √âviter le rate limiting
                
                # Affichage des r√©sultats √âtape 1
                st.markdown("### üìã √âtape 1 - Requ√™tes collect√©es")
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Requ√™tes collect√©es", len(llm_responses))
                with col2:
                    st.metric("Requ√™tes uniques", len(set(llm_responses)))
                
                # D√©doublonnage pour √©tape 2
                status_text.text("‚è≥ √âtape 2/3: Affinage et s√©lection...")
                progress_bar.progress(70)
                
                deduplicated_queries = deduplicate_queries(llm_responses)
                queries_list = "\n".join([f"- {query}" for query in deduplicated_queries])
                
                prompt_etape2 = f"""En te basant sur la th√©matique '{thematique}' et sur cette liste de requ√™tes conversationnelles, fais-moi une s√©lection d'un top 10 des meilleures requ√™tes conversationnelles :

{queries_list}

Crit√®res de s√©lection :
- Pertinence pour la th√©matique
- Potentiel de volume de recherche
- Intention de recherche claire
- Adaptabilit√© au SEO conversationnel"""

                refined_response = call_gpt4o_mini(prompt_etape2)
                refined_queries = extract_queries_from_response(refined_response) if refined_response else []
                
                progress_bar.progress(85)
                
                # √âtape 3: Finalisation
                status_text.text("‚è≥ √âtape 3/3: Finalisation par intention de recherche...")
                
                if refined_queries:
                    final_queries_list = "\n".join([f"- {query}" for query in refined_queries])
                    prompt_etape3 = f"""En te basant sur l'intention de recherche, d√©doublonne cette liste et fournis-moi le top 10 des meilleures requ√™tes conversationnelles pour la th√©matique '{thematique}':

{final_queries_list}

Analyse chaque requ√™te selon :
1. L'intention de recherche (informationnelle, navigationnelle, transactionnelle)
2. Le potentiel SEO
3. La pertinence pour les assistants vocaux
4. L'adaptabilit√© au contenu conversationnel

Pr√©sente le r√©sultat final sous forme de liste num√©rot√©e."""
                    
                    final_response = call_gpt4o_mini(prompt_etape3)
                    final_queries = extract_queries_from_response(final_response) if final_response else refined_queries
                else:
                    final_queries = []
                
                progress_bar.progress(100)
                status_text.text("‚úÖ Analyse termin√©e !")
                
                # Affichage des r√©sultats finaux
                st.markdown("### üèÜ R√©sultats finaux - Top 10 des requ√™tes conversationnelles")
                
                if final_queries:
                    # M√©triques
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Requ√™tes finales", len(final_queries))
                    with col2:
                        st.metric("Taux de conversion", f"{(len(final_queries)/max(len(llm_responses), 1)*100):.1f}%")
                    with col3:
                        st.metric("√âtapes compl√©t√©es", "3/3")
                    
                    # Liste des requ√™tes finales
                    st.markdown("#### üìù Requ√™tes s√©lectionn√©es:")
                    for i, query in enumerate(final_queries, 1):
                        st.markdown(f"**{i}.** {query}")
                    
                    # Export des donn√©es
                    st.markdown("### üì§ Export des r√©sultats")
                    
                    # Cr√©ation du DataFrame pour export
                    export_data = {
                        'Rang': range(1, len(final_queries) + 1),
                        'Requ√™te conversationnelle': final_queries,
                        'Th√©matique': [thematique] * len(final_queries)
                    }
                    df = pd.DataFrame(export_data)
                    
                    # Boutons d'export
                    col1, col2 = st.columns(2)
                    with col1:
                        csv = df.to_csv(index=False, encoding='utf-8')
                        st.download_button(
                            label="üìä T√©l√©charger CSV",
                            data=csv,
                            file_name=f"requetes_conversationnelles_{thematique.replace(' ', '_')}.csv",
                            mime="text/csv"
                        )
                    
                    with col2:
                        json_data = df.to_json(orient='records', force_ascii=False, indent=2)
                        st.download_button(
                            label="üìã T√©l√©charger JSON",
                            data=json_data,
                            file_name=f"requetes_conversationnelles_{thematique.replace(' ', '_')}.json",
                            mime="application/json"
                        )
                    
                    # Analyse d√©taill√©e
                    with st.expander("üìä Analyse d√©taill√©e du processus"):
                        st.markdown(f"**Th√©matique analys√©e:** {thematique}")
                        st.markdown(f"**Requ√™tes collect√©es initialement:** {len(llm_responses)}")
                        st.markdown(f"**Requ√™tes apr√®s d√©doublonnage:** {len(deduplicated_queries)}")
                        st.markdown(f"**Requ√™tes finales s√©lectionn√©es:** {len(final_queries)}")
                        st.markdown(f"**Efficacit√© du processus:** {(len(final_queries)/max(len(llm_responses), 1)*100):.1f}%")
                
                else:
                    st.error("‚ùå Aucune requ√™te n'a pu √™tre extraite. V√©rifiez votre th√©matique et r√©essayez.")

    else:
        # Instructions d'utilisation pour l'analyse th√©matique
        st.markdown("""
        ## üìñ Instructions d'utilisation - Analyse Th√©matique
        
        1. **Configurez votre cl√© API OpenAI** dans la barre lat√©rale
        2. **Entrez la th√©matique** √† analyser dans le champ ci-dessus
        3. **Cliquez sur "Lancer l'analyse th√©matique compl√®te"** pour d√©marrer le processus
        
        ### üéØ Exemples de th√©matiques:
        - "R√©servation restaurant en ligne"
        - "Formation d√©veloppement web"
        - "Voyage √©cologique et durable"
        - "E-commerce produits bio"
        - "Coaching personnel √† distance"
        
        ### ‚ö° Le processus automatis√© comprend:
        - **√âtape 1:** Collecte initiale via GPT-4o mini avec variations
        - **√âtape 2:** Affinage et s√©lection des meilleures requ√™tes
        - **√âtape 3:** Finalisation bas√©e sur l'intention de recherche
        - **Export:** T√©l√©chargement des r√©sultats en CSV/JSON
        """)

# Instructions globales
if not api_key:
    st.markdown("""
    ## üìñ Instructions g√©n√©rales
    
    ### üîç Analyse par Suggestions Google (Recommand√©e)
    
    **Fonctionnalit√©s am√©lior√©es:**
    - **Configuration flexible:** Choisissez le nombre de suggestions et questions finales
    - **G√©n√©ration syst√©matique:** 10 questions par suggestion Google
    - **Consolidation intelligente:** D√©duplication avec scoring de pertinence
    - **Export optimis√©:** Excel format√© et JSON avec m√©tadonn√©es
    
    **Processus d'ex√©cution:**
    1. Collecte des suggestions Google pour chaque mot-cl√©
    2. G√©n√©ration de 10 questions conversationnelles par suggestion
    3. Consolidation et d√©duplication des questions
    4. Export par ordre de pertinence d√©croissante
    
    ### ‚öôÔ∏è Configuration requise:
    - Cl√© API OpenAI (configur√©e dans la barre lat√©rale)
    - Connexion internet pour les suggestions Google
    """)

# Footer
st.markdown("---")
st.markdown("*Outil d'optimisation SEO pour requ√™tes conversationnelles | Powered by GPT-4o mini & Streamlit*")
